{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "GUhMPm2dg4rD"
      },
      "outputs": [],
      "source": [
        "# --- Install Required Packages ---\n",
        "!pip install -q huggingface-hub==0.27.1 llama-index==0.10.57 llama-index-vector-stores-chroma==0.1.10 google-generativeai==0.5.4 openai==1.59.8 chromadb==0.5.5 nest_asyncio tiktoken==0.8.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUW00RN1oZAk"
      },
      "source": [
        "# Setup LlamaIndex and download RAG data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cT0AUaKWlJA9"
      },
      "outputs": [],
      "source": [
        "# --- Set Environment Variables ---\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "\n",
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mIN6JeYNG1Lq"
      },
      "outputs": [],
      "source": [
        "# --- Load LLM and Embeddings ---\n",
        "from llama_index.llms.openai import OpenAI\n",
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "from llama_index.core import Settings\n",
        "\n",
        "Settings.llm = OpenAI(temperature=0.7, model=\"gpt-4o-mini\")\n",
        "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337,
          "referenced_widgets": [
            "f430d1b2477f4c3eb5e3d7a398c423a2",
            "00991f89b5164e3eb5675c6ed5282d58",
            "8007617e21dc461bbb8051eefc72a04f",
            "028f9e9332fb421b8b8fc1289920856d",
            "d5cad02fa1574ec094a7fc7d20d720d9",
            "ab8b7cfac0e941df9f3b3f0d79f9472a",
            "e3f0e691660f451cbdcba99d72a45e30",
            "26de460e5c8a451ea73579840865890d",
            "b5b05748c292474b9ff01ae8eb140f7c",
            "6ebc7d3a0ca54526a0b38633951827a4",
            "6a6c45a2f81b42cfbd5c385c4fb6dc21"
          ]
        },
        "id": "X5mdMdAUFvrH",
        "outputId": "e4488dc0-47bc-42ca-cb6c-a9cee1b4022d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f430d1b2477f4c3eb5e3d7a398c423a2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vectorstore.zip:   0%|          | 0.00/97.2M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/vectorstore.zip\n",
            "   creating: /content/ai_tutor_knowledge/\n",
            "   creating: /content/ai_tutor_knowledge/684af133-f877-4230-bde4-575cf53b6688/\n",
            "  inflating: /content/ai_tutor_knowledge/684af133-f877-4230-bde4-575cf53b6688/length.bin  \n",
            "  inflating: /content/ai_tutor_knowledge/684af133-f877-4230-bde4-575cf53b6688/index_metadata.pickle  \n",
            "  inflating: /content/ai_tutor_knowledge/684af133-f877-4230-bde4-575cf53b6688/link_lists.bin  \n",
            "  inflating: /content/ai_tutor_knowledge/684af133-f877-4230-bde4-575cf53b6688/header.bin  \n",
            "  inflating: /content/ai_tutor_knowledge/684af133-f877-4230-bde4-575cf53b6688/data_level0.bin  \n",
            "  inflating: /content/ai_tutor_knowledge/chroma.sqlite3  \n"
          ]
        }
      ],
      "source": [
        "# --- Download Vector Store from Hugging Face Hub ---\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "vectorstore = hf_hub_download(\n",
        "    repo_id=\"jaiganesan/ai_tutor_knowledge\",\n",
        "    filename=\"vectorstore.zip\",\n",
        "    repo_type=\"dataset\",\n",
        "    local_dir=\"/content\"\n",
        ")\n",
        "\n",
        "!unzip -o /content/vectorstore.zip -d /content/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84f0Q30MoaLY"
      },
      "source": [
        "# Create RAG pipeline (i.e. the query engine)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jaA88PY0ld53"
      },
      "outputs": [],
      "source": [
        "# --- Create RAG Pipeline ---\n",
        "import chromadb\n",
        "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
        "from llama_index.core import VectorStoreIndex\n",
        "\n",
        "\n",
        "# We could hide this logic in the presentation...\n",
        "def get_query_engine_and_vector_store(top_k=5):\n",
        "    chroma_client = chromadb.PersistentClient(path=\"/content/ai_tutor_knowledge\")\n",
        "    chroma_collection = chroma_client.get_or_create_collection(\"ai_tutor_knowledge\")\n",
        "    vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
        "    index = VectorStoreIndex.from_vector_store(vector_store=vector_store)\n",
        "    query_engine = index.as_query_engine(similarity_top_k=top_k)\n",
        "    return query_engine, vector_store\n",
        "\n",
        "\n",
        "# Create a query engine with a chosen top_k\n",
        "query_engine, vector_store = get_query_engine_and_vector_store(top_k=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyVUclyhobzf"
      },
      "source": [
        "# Let's test the RAG pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JAtRAQfmcA7",
        "outputId": "4c496cfb-7585-4690-d450-9b000ae79e54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query: How does Parameter Efficient Fine-Tuning (PEFT) work?\n",
            "Answer: Parameter-Efficient Fine-Tuning (PEFT) is designed to adapt large pretrained models to various downstream applications without necessitating the fine-tuning of all model parameters. Instead, PEFT methods focus on fine-tuning a limited number of additional parameters, which significantly reduces both computational and storage costs while achieving performance that is comparable to fully fine-tuned models. This approach enhances accessibility for training and storing large language models on consumer hardware.\n",
            "\n",
            "PEFT integrates with popular libraries such as Transformers, Diffusers, and Accelerate, facilitating faster and more efficient processes for loading, training, and utilizing large models for inference. The library also provides resources, including practical how-to guides and conceptual guides, to assist users in applying PEFT methods across different tasks, such as image classification and language modeling.\n"
          ]
        }
      ],
      "source": [
        "# Test the RAG Pipeline\n",
        "example_query = \"How does Parameter Efficient Fine-Tuning (PEFT) work?\"\n",
        "response = query_engine.query(example_query)\n",
        "print(\"Query:\", example_query)\n",
        "print(\"Answer:\", response.response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4lfl2DB2WPD"
      },
      "source": [
        "# See and update the prompt of the RAG pipeline. It's not necessary to show this in the presentation I think... To be used after the prompt optimization to change the RAG prompt with the optimized one"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "lKeGRJBW1xw7",
        "outputId": "e3bed36c-52b6-4447-a1ff-1630432bbbb6"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "**Prompt Key**: response_synthesizer:text_qa_template<br>**Text:** <br>"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Context information is below.\n",
            "---------------------\n",
            "{context_str}\n",
            "---------------------\n",
            "Given the context information and not prior knowledge, answer the query.\n",
            "Query: {query_str}\n",
            "Answer: \n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "<br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "**Prompt Key**: response_synthesizer:refine_template<br>**Text:** <br>"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The original query is as follows: {query_str}\n",
            "We have provided an existing answer: {existing_answer}\n",
            "We have the opportunity to refine the existing answer (only if needed) with some more context below.\n",
            "------------\n",
            "{context_msg}\n",
            "------------\n",
            "Given the new context, refine the original answer to better answer the query. If the context isn't useful, return the original answer.\n",
            "Refined Answer: \n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "<br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Let's see what prompt is used by the query engine\n",
        "import json\n",
        "from IPython.display import Markdown\n",
        "\n",
        "\n",
        "def display_prompt_dict(prompts_dict):\n",
        "    for k, p in prompts_dict.items():\n",
        "        text_md = f\"**Prompt Key**: {k}<br>\" f\"**Text:** <br>\"\n",
        "        display(Markdown(text_md))\n",
        "        print(p.get_template())\n",
        "        display(Markdown(\"<br><br>\"))\n",
        "\n",
        "\n",
        "prompts_dict = query_engine.get_prompts()\n",
        "display_prompt_dict(prompts_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lwi3Bf1o1-xF"
      },
      "outputs": [],
      "source": [
        "# Let's edit the \"response_synthesizer:text_qa_template\" prompt, which is\n",
        "# the one used when we call `query_engine.query(...)`\n",
        "from llama_index.core import PromptTemplate\n",
        "\n",
        "PROMPT_TEMPLATE_ORIGINAL = \"\"\"\\\n",
        "Context information is below.\n",
        "---------------------\n",
        "{context_str}\n",
        "---------------------\n",
        "Given the context information and not prior knowledge, answer the query.\n",
        "Query: {query_str}\n",
        "Answer: \\\n",
        "\"\"\"\n",
        "\n",
        "PROMPT_TEMPLATE_NEW = \"\"\"\\\n",
        "Context information is below.\n",
        "---------------------\n",
        "{context_str}\n",
        "---------------------\n",
        "\n",
        "Given the context information and not prior knowledge, answer the query.\n",
        "Answer in the style of Shakespear.\n",
        "\n",
        "Query: {query_str}\n",
        "Answer: \\\n",
        "\"\"\"\n",
        "\n",
        "query_engine.update_prompts(\n",
        "    {\"response_synthesizer:text_qa_template\": PromptTemplate(PROMPT_TEMPLATE_NEW)}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zh_s1PGG27ZS",
        "outputId": "72be8a58-5fa2-4bde-8c2e-c7d332ce2061"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query: How does Parameter Efficient Fine-Tuning (PEFT) work?\n",
            "Answer: Oh, fair inquirer, lend me thine ear,  \n",
            "For I shall weave a tale both bright and clear.  \n",
            "Parameter Efficient Fine-Tuning, PEFT by name,  \n",
            "Doth offer a path to model's acclaim.  \n",
            "\n",
            "In yonder realm of vast and learned art,  \n",
            "Where pretrained giants doth play their part,  \n",
            "PEFT, a cunning craft, doth arise,  \n",
            "To adapt these titans, to reach for the skies.  \n",
            "\n",
            "With but a handful of parameters to train,  \n",
            "It lightens the load, reduces the strain.  \n",
            "No longer must all weights be cast in the fray,  \n",
            "For but a few, like stars, can lead the way.  \n",
            "\n",
            "Through methods diverse, like LoRA's embrace,  \n",
            "Or the FourierFT's swift, elegant grace,  \n",
            "The essence remains: to fine-tune with care,  \n",
            "While preserving the wisdom these models do bear.  \n",
            "\n",
            "Integration with libraries, a seamless affair,  \n",
            "Transformers and Diffusers, they flourish with flair.  \n",
            "Faster the training, smoother the flow,  \n",
            "As PEFT doth guide us to heights we may know.  \n",
            "\n",
            "So, gentle friend, in this fine-tuning quest,  \n",
            "PEFT stands as a beacon, a means to invest,  \n",
            "In knowledge and power, with efficiency grand,  \n",
            "A new age of learning at our command.\n"
          ]
        }
      ],
      "source": [
        "# Test the RAG pipeline with the new prompt\n",
        "example_query = \"How does Parameter Efficient Fine-Tuning (PEFT) work?\"\n",
        "response = query_engine.query(example_query)\n",
        "print(\"Query:\", example_query)\n",
        "print(\"Answer:\", response.response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u33JxzWe4hWo"
      },
      "outputs": [],
      "source": [
        "# Let's put back the original prompt\n",
        "query_engine.update_prompts(\n",
        "    {\"response_synthesizer:text_qa_template\": PromptTemplate(PROMPT_TEMPLATE_ORIGINAL)}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Up7QViyLogfN"
      },
      "source": [
        "# Let's create an evaluation dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtEmp9w-5jFG"
      },
      "source": [
        "We're going to get a dataset that will be analysed by a domain expert to learn more about the data and the task, and to ultimately improve the prompt of the RAG pipeline.\n",
        "\n",
        "To jump-start this process, we use an LLM to generate questions from documents. Ideally, one would ask the domain expert to write them or they would be collected from real-world questions asked by the users."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZssxCaf9pAJG"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.llms.utils import LLM\n",
        "from llama_index.core.schema import MetadataMode, TextNode\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "import re\n",
        "import uuid\n",
        "import warnings\n",
        "import time\n",
        "from typing import Dict, List, Tuple\n",
        "from llama_index.core.evaluation import EmbeddingQAFinetuneDataset\n",
        "\n",
        "DEFAULT_QA_GENERATE_PROMPT_TMPL = \"\"\"\\\n",
        "I'm developing an AI tutor whose job is to answer questions about Artificial \\\n",
        "Intelligence from students. The AI tutor has a knowledge base of documents that \\\n",
        "leverages to answer questions from students.\n",
        "\n",
        "Your task is to write questions that students would ask about AI. In particular, \\\n",
        "the questions that you have to write should be answerable with information \\\n",
        "present the following context, but consider that the student doesn't know that context \\\n",
        "in advance (so, the questions can't mention parts of the context).\n",
        "\n",
        "Context:\n",
        "---------------------\n",
        "{context_str}\n",
        "---------------------\n",
        "\n",
        "Given the context information above and no prior knowledge, \\\n",
        "write {num_questions_per_chunk} questions that a student may ask.\n",
        "The questions should be diverse in nature.\n",
        "Restrict the questions to the context information provided.\n",
        "The questions can't refer to the existence of the source context.\n",
        "\n",
        "Here are some examples of good and bad questions:\n",
        "-----\n",
        "Question: What was the primary purpose of developing the AI-powered solution mentioned in the text?\n",
        "Quality: Bad.\n",
        "Critique: The question says \"mentioned in the text\", it can't refer to the existence \\\n",
        "of the source context. \\\n",
        "Since the user can't see the source context, he can't know what is the provided text and \\\n",
        "therefore he can't answer the question.\n",
        "-----\n",
        "Question: What is the primary purpose of developing the XYZ AI-powered solution?\n",
        "Quality: Good.\n",
        "Critique: The question is self-contained and atomic.\n",
        "-----\n",
        "Question: What is the range of the numerical values provided in the data?\n",
        "Quality: Bad.\n",
        "Critique: The question can't refer to the source context directly and this question \\\n",
        "says \"provided in the data\". It must be self-contained and atomic. \\\n",
        "Since the user can't see the source context, he can't know what is the provided data and \\\n",
        "therefore he can't answer the question.\n",
        "-----\n",
        "Question: What was the primary purpose of developing the AI-powered solution?\n",
        "Quality: Bad.\n",
        "Critique: It is not clear what solution it is talking about, it is not self-contained and atomic. \\\n",
        "Since the user can't see the source context, he can't know what is the solution mentioned and \\\n",
        "therefore he can't answer the question.\n",
        "-----\n",
        "Question: What technology was integrated with Slack for internal use in the AI-powered solution project mentioned?\n",
        "Quality: Bad.\n",
        "Critique: It is not clear what solution it is talking about, it is not self-contained and atomic. \\\n",
        "Since the user can't see the source context, he can't know what is the project mentioned and \\\n",
        "therefore he can't answer the question.\n",
        "-----\n",
        "Question: What is the main consequence of model quantization in terms of accuracy and expressive power?\n",
        "Quality: Good.\n",
        "Critique: The question is self-contained and atomic.\n",
        "-----\n",
        "\n",
        "Write one question per line. If it's not possible to generate self-contained and atomic \\\n",
        "questions because of the nature of the context, then simply write \"NONE\".\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def generate_question_context_pairs(\n",
        "    nodes: List[TextNode],\n",
        "    llm: LLM,\n",
        "    qa_generate_prompt_tmpl: str = DEFAULT_QA_GENERATE_PROMPT_TMPL,\n",
        "    num_questions_per_chunk: int = 2,\n",
        "    request_delay: float = 2.0,\n",
        ") -> EmbeddingQAFinetuneDataset:\n",
        "    \"\"\"Generate examples given a set of nodes with delays between requests.\"\"\"\n",
        "    node_dict = {\n",
        "        node.node_id: node.get_content(metadata_mode=MetadataMode.NONE)\n",
        "        for node in nodes\n",
        "    }\n",
        "\n",
        "    queries = {}\n",
        "    relevant_docs = {}\n",
        "\n",
        "    for node_id, text in tqdm(node_dict.items()):\n",
        "        query = qa_generate_prompt_tmpl.format(\n",
        "            context_str=text, num_questions_per_chunk=num_questions_per_chunk\n",
        "        )\n",
        "        response = str(llm.complete(query))\n",
        "\n",
        "        if \"NONE\" in response:\n",
        "            continue\n",
        "\n",
        "        result = response.strip().split(\"\\n\")\n",
        "        questions = [\n",
        "            re.sub(r\"^\\d+[\\).\\s]\", \"\", question).strip() for question in result\n",
        "        ]\n",
        "        questions = [question for question in questions if len(question) > 0][\n",
        "            :num_questions_per_chunk\n",
        "        ]\n",
        "\n",
        "        num_questions_generated = len(questions)\n",
        "        if num_questions_generated < num_questions_per_chunk:\n",
        "            warnings.warn(\n",
        "                f\"Fewer questions generated ({num_questions_generated}) \"\n",
        "                f\"than requested ({num_questions_per_chunk}).\"\n",
        "            )\n",
        "\n",
        "        for question in questions:\n",
        "            question_id = str(uuid.uuid4())\n",
        "            queries[question_id] = question\n",
        "            relevant_docs[question_id] = [node_id]\n",
        "\n",
        "        time.sleep(request_delay)\n",
        "\n",
        "    return EmbeddingQAFinetuneDataset(\n",
        "        queries=queries, corpus=node_dict, relevant_docs=relevant_docs\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOHlpDcylk1T",
        "outputId": "1c8b7a9f-6f0e-4e00-c82a-1bf9b76b6ce6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 50/50 [01:55<00:00,  2.31s/it]\n"
          ]
        }
      ],
      "source": [
        "# We use the GPT-4o model for generating synthetic question-context pairs.\n",
        "\n",
        "# Retrieve all the nodes from the docstore for question generation\n",
        "all_nodes = vector_store.get_nodes([])\n",
        "\n",
        "# Create an instance of GPT-4o to generate questions\n",
        "gen_llm = OpenAI(temperature=0.7, model=\"gpt-4o\")\n",
        "\n",
        "# Generate a smaller dataset to avoid excessive calls\n",
        "rag_eval_dataset = generate_question_context_pairs(\n",
        "    nodes=all_nodes[:50], llm=gen_llm, num_questions_per_chunk=1, request_delay=2.0\n",
        ")\n",
        "\n",
        "# Save dataset locally\n",
        "rag_eval_dataset.save_json(\"./synthetic_rag_eval_dataset.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvriUqjroxnN",
        "outputId": "7484ebbf-8f98-4527-d2cc-9aede617e523"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of queries in dataset: 34\n"
          ]
        }
      ],
      "source": [
        "# Reload the dataset (optional)\n",
        "rag_eval_dataset = EmbeddingQAFinetuneDataset.from_json(\n",
        "    \"./synthetic_rag_eval_dataset.json\"\n",
        ")\n",
        "print(f\"Number of queries in dataset: {len(rag_eval_dataset.queries)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Roqq63NB7PTa"
      },
      "source": [
        "# Review and clean the generated questions\n",
        "\n",
        "Since we generated the questions synthetically, let's review them with a widget. We'll keep only the most-representative and varied questions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538,
          "referenced_widgets": [
            "ef1195a2b2ed40bda5254efb4598b3e8",
            "ce789ed25b914081a269f95da23ae708",
            "9d9ad3daab8845baab4e358a60b4d3bf",
            "4665b831c005427dbadd8f90dc183233",
            "cb1b144fa4d64601a2c5639322587eb5",
            "0457d91c5b914948b8104ca3fdde7a04",
            "a36450dc92cd49ac8e0aa0907de60c45",
            "ac770f29e10e461abb60c68f84daf21c",
            "2ecb1abf3a7b4ccfbc211ac254046a34",
            "584412541c72435997a177cb04a79cb9",
            "0c9465f6204e4ce4a3fc426c6755bd4a",
            "f91e19d4ba1d4cfaa7b146332ca777e2",
            "202c31bc92a941a9a52d6fd02926c1be",
            "7dbd4bdeabcf43788c5067004d02404d",
            "b8a7413f80a04088ad89f044201a56ef",
            "031b3786d01a4572add8fd266904a02e",
            "0d69049ecbae4d1097a36d74bfb50475",
            "21f23d1671a5451fa5df72b68a2c775e",
            "c2f2e9a5941443f6bb1f26329f659ea4",
            "92c527b12b57485fa6cc6d745e1abefe",
            "96832da295d24ac6864b7da2e4ed3087",
            "f7cd3613666940bea33f4f8ac3998dbb",
            "fa0c3658c7e64b7f8749959f0e33c799",
            "d4d15e642fa1429b94cc378b735abb57",
            "8ac95b6cf5c44c47afc9e36ca682604b",
            "0894f9b02b054c1b8294863e4c0e9d22",
            "12ebdefaf16147489eb1659359b4fc5e",
            "cb6d92ff49d44b828ecd0d5fa9bbe84e",
            "33bcbd92355e4990955147551fa2f344",
            "95d25b8aa4ed4aaeb960c66186b14143",
            "5078ffc458d7476d99583d000d5522fa",
            "d716718ff04e4e2ca10944add879998a",
            "573a78fe4fee4b36ad5a9e9a7e6c6191",
            "f34717b08ae94c4c92f6f91a16af0373",
            "6666877048954f5cbb264d409cedd180",
            "694f559a5fa540609a3f6ade929ad839",
            "64a3d1b8b20b436cae5b4bfa73a76928",
            "da34a0498d8b42d787eb9d9115213f54",
            "bf2c9d27e7de4320a4872b9433a3acc7",
            "a5330fc4934e4b11ad2fde2e66639509",
            "01af4de4ded143408cc21277c48d3fba",
            "04e2e201c83a41f59780fa898608f586",
            "57e6a71579724edb9bd311a6fda394f0",
            "4c80aa96b8a24969b1efa5aaa130aec9",
            "1fb1a2034cd44e46a0b897bda068c2b5",
            "bb2367bd986e4c01ae25d97e24f1d267",
            "df6396dd4d244a42b210f367698408b5",
            "eecaa41ff1074b13ac3281c33d2fac6c",
            "5fe674b691844723852b7acb115d3b15",
            "38694b49940a4273a393e7b9fbfeea1d",
            "1944196a72244f5b9a88b26af5341723",
            "57cefad1900a4cd5be182cc3ef9c2b14",
            "6df1744835b0460b854eda9588005cb5",
            "9154b46948dd44ceafc88c103f5ea03a",
            "6bd018a2cad54e20af701860d41da47b",
            "9e8cf7d2d1ea4e2c98555310e9c96d53",
            "24a76caa2e064b26be50a5c4a2d5150a",
            "f1b2f2d8b18947e7b8671b3311982630",
            "a968983ee37045e098dae1aed98616eb",
            "7a41e193c34d4713990ac03f84f49388",
            "395d0abdd8bc4224bd45fc83a4d4023e",
            "5acea6494e3b41f89ad05920b67a2119",
            "b0c0532b701b437086ea7ca3f9a8fe77",
            "d75cae49da7c44bf93e208514f9f9c7e",
            "3092aa0eb3f1492fbb07112cea468bc4",
            "1439a53a48f04e9ea8254dfe88719590",
            "76a02c5eecec4c5fa2596be5b31b8c6a",
            "749a7ebbe8004bbf867924501e88054c",
            "5e3766eaa0c34c42ac48d64756b87779",
            "b961b20951244ead9ea4d4ef020b0249",
            "525cc951c52942a09786a42958fabfb6",
            "7e7292f27b0342e48b1615179372ffde",
            "31e9231f195440868a85b0767fa6c693",
            "a47b856fe74e4014bffe69738e42feb9",
            "4a835f9aae4c410e90254cb2eb11d732",
            "5d37cee48c524be9a5589f0ebaa7e307",
            "2edbfea2ae114012bfb894bdb6e823ef",
            "d2c5b448888d4cae811bf51421f62151",
            "39f8a4782c4944ef8d1ed3b3856730ca",
            "87696977eb014b23ac137e5f52840f1f",
            "d0832c42f8dc4df98d42d5ebd8ef50a8",
            "9635faa543c545f4a1087630e35266e1",
            "80764679b76243f684ff1a4a85bb1f17",
            "c71f9f4460bd438ab3c5eb6f029e3fdb",
            "cb2063163f344327b47855fe840f3e4c",
            "922bdc1668354697b2b470473afd1ca8",
            "e35f7793b5d147d3a93740bda87472bf",
            "4d9d69d58aaf48759052cf4bd92c3cdd",
            "9e69309e4ad946fca33f7cba74d6ddf4",
            "52f0058d9a4e408cb108bb349a16e07a",
            "41e003ce91534d93a2412b025e6efe6c",
            "4e47b4a8b0ac41f5b4c02790579eff3c",
            "ae38a53b616c4bc3a2115615dffc935e",
            "97a69a1020e441cca91515d446ccf070",
            "b255b421f6a74e53bf6a781d3c978024",
            "9b2ebad1f9f74a63b4fa6c4a7e1ffbe7",
            "912e3eebd5394d19abb5d9d8cb5fbc64",
            "74658f35f4a74e65abab0fcdb10afc5a",
            "9f13a589664c40228dfd91fb1724744a",
            "8bdead914c3f481c976f2aa769742747",
            "598672c85fc3450b8e4108d2b4e65c7c",
            "8bfecb3c0f2c492f8751db0a13e145ba",
            "44bb89824ed645e28eb43a2cd2eb1e1f",
            "8c861eb631b045d3ae1f419e5a9fcd7a",
            "38495dface7249bbb132bbbb986316b8",
            "60eb932b5d0f40a889a9c0a736b66966",
            "958b423db36741d091bb3a5c99a26d93"
          ]
        },
        "id": "FSPEacDr7RW5",
        "outputId": "a2c99146-af66-4679-b355-da627ec91ff7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Review the questions below and uncheck those that are invalid or undesirable.\n",
            "Scroll within the box to see all questions. Then click 'Save Cleaned Dataset':\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ef1195a2b2ed40bda5254efb4598b3e8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Checkbox(value=True, description='What are some strategies to improve the performance of a RAG …"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "38495dface7249bbb132bbbb986316b8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Button(button_style='success', description='Save Cleaned Dataset', style=ButtonStyle())"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Cleaned dataset saved to 'cleaned_rag_eval_dataset.json'.\n"
          ]
        }
      ],
      "source": [
        "# --- Review & Clean Generated Questions ---\n",
        "\n",
        "import json\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "# Load the synthetic RAG evaluation dataset\n",
        "with open(\"synthetic_rag_eval_dataset.json\", \"r\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "queries = data[\"queries\"]\n",
        "corpus = data[\"corpus\"]\n",
        "relevant_docs = data[\"relevant_docs\"]\n",
        "\n",
        "# Dictionary to store checkboxes for each question\n",
        "check_boxes = {}\n",
        "\n",
        "# Create a list of checkboxes, one for each question\n",
        "checkbox_list = []\n",
        "for qid, question in queries.items():\n",
        "    checkbox = widgets.Checkbox(\n",
        "        value=True,\n",
        "        description=question,\n",
        "        indent=False,\n",
        "        layout=widgets.Layout(width=\"100%\"),  # ensure there's enough horizontal space\n",
        "        style={\"description_width\": \"initial\"},  # prevent truncation of description\n",
        "    )\n",
        "    check_boxes[qid] = checkbox\n",
        "    checkbox_list.append(checkbox)\n",
        "\n",
        "# Make a scrollable container for all the checkboxes\n",
        "box_layout = widgets.Layout(\n",
        "    overflow_y=\"scroll\",\n",
        "    border=\"1px solid gray\",\n",
        "    width=\"auto\",\n",
        "    height=\"400px\",  # adjust this height as needed\n",
        ")\n",
        "scrollable_box = widgets.VBox(checkbox_list, layout=box_layout)\n",
        "\n",
        "print(\"Review the questions below and uncheck those that are invalid or undesirable.\")\n",
        "print(\n",
        "    \"Scroll within the box to see all questions. Then click 'Save Cleaned Dataset':\\n\"\n",
        ")\n",
        "\n",
        "display(scrollable_box)\n",
        "\n",
        "\n",
        "def save_cleaned_dataset(_):\n",
        "    # Gather checked (kept) questions\n",
        "    new_queries = {}\n",
        "    new_relevant_docs = {}\n",
        "\n",
        "    for qid, cb in check_boxes.items():\n",
        "        if cb.value:  # user wants to keep this question\n",
        "            new_queries[qid] = queries[qid]\n",
        "            new_relevant_docs[qid] = relevant_docs[qid]\n",
        "\n",
        "    # Build a new dataset dict\n",
        "    cleaned_data = {\n",
        "        \"queries\": new_queries,\n",
        "        \"corpus\": corpus,\n",
        "        \"relevant_docs\": new_relevant_docs,\n",
        "    }\n",
        "\n",
        "    # Save the cleaned dataset\n",
        "    with open(\"cleaned_rag_eval_dataset.json\", \"w\") as f:\n",
        "        json.dump(cleaned_data, f, indent=4)\n",
        "\n",
        "    print(\"\\nCleaned dataset saved to 'cleaned_rag_eval_dataset.json'.\")\n",
        "\n",
        "\n",
        "# Create and display the \"Save Cleaned Dataset\" button\n",
        "save_button = widgets.Button(description=\"Save Cleaned Dataset\", button_style=\"success\")\n",
        "save_button.on_click(save_cleaned_dataset)\n",
        "\n",
        "display(save_button)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bl2OsAGLZw_",
        "outputId": "80b64a04-757c-4e4f-d44a-1499ef9078a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of queries in dataset: 27\n"
          ]
        }
      ],
      "source": [
        "# Load the cleaned dataset\n",
        "rag_eval_dataset = EmbeddingQAFinetuneDataset.from_json(\n",
        "    \"./cleaned_rag_eval_dataset.json\"\n",
        ")\n",
        "print(f\"Number of queries in dataset: {len(rag_eval_dataset.queries)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bu5IeQtmLpLo"
      },
      "source": [
        "# Generate answers to all the queries in the eval dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66IAZHZNf_b1"
      },
      "source": [
        "Then, let's use our RAG pipeline to answer all the questions of the evaluation dataset. Ideally, if we got the questions of the evaluation dataset from real-world data, we'd be able to get their responses from the same real-world data as well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixuqj3Nb1rqy",
        "outputId": "4470e857-d560-410f-b6c6-35e112da1b09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/27\n",
            "2/27\n",
            "3/27\n",
            "4/27\n",
            "5/27\n",
            "6/27\n",
            "7/27\n",
            "8/27\n",
            "9/27\n",
            "10/27\n",
            "11/27\n",
            "12/27\n",
            "13/27\n",
            "14/27\n",
            "15/27\n",
            "16/27\n",
            "17/27\n",
            "18/27\n",
            "19/27\n",
            "20/27\n",
            "21/27\n",
            "22/27\n",
            "23/27\n",
            "24/27\n",
            "25/27\n",
            "26/27\n",
            "27/27\n"
          ]
        }
      ],
      "source": [
        "# Use the query engine to answer all the queries in the eval dataset\n",
        "\n",
        "# Retrieve the prompt template used by the query engine\n",
        "prompts_dict = query_engine.get_prompts()\n",
        "text_qa_template = prompts_dict[\"response_synthesizer:text_qa_template\"].get_template()\n",
        "\n",
        "template_query_context_answer = []\n",
        "for i, question in enumerate(rag_eval_dataset.queries.values(), start=1):\n",
        "    print(f\"{i}/{len(rag_eval_dataset.queries)}\")\n",
        "\n",
        "    # Get response from RAG\n",
        "    response = query_engine.query(question)\n",
        "\n",
        "    # Retrieve the formatted prompt with context\n",
        "    context_str = \"\"\n",
        "    for i, node in enumerate(response.source_nodes, start=1):\n",
        "        context_str += f\"Source {i}:\\n-----\\n{node.get_content().strip()}\\n-----\\n\\n\"\n",
        "    context_str = context_str.strip()\n",
        "    prompt_with_context_query = text_qa_template.format(\n",
        "        context_str=context_str, query_str=question\n",
        "    )\n",
        "\n",
        "    # Save the formatted prompt with context\n",
        "    template_query_context_answer.append(\n",
        "        {\n",
        "            \"query\": question,\n",
        "            \"prompt\": prompt_with_context_query,\n",
        "            \"response\": response.response,\n",
        "        }\n",
        "    )\n",
        "\n",
        "\n",
        "# Save to a JSON file\n",
        "with open(\"rag_eval_dataset_with_responses.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(template_query_context_answer, f, indent=4, ensure_ascii=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M13LI5MRMRQn"
      },
      "source": [
        "# Domain expert annotates the data with a yes/no label and a critique"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2bfGJP-RvHk"
      },
      "source": [
        "Here we pretend that we had the domain expert reviewing every pair of <prompt, response> and assigning a label \"Good\" or \"Bad\" and writing a critique about the reasoning behind the choice of the label.\n",
        "\n",
        "Instead, what I did here it using o1-pro to write them for me... and I saved the final file as \"rag_eval_dataset_with_labels.json\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "06d8LN_CVenF",
        "outputId": "e31fad4a-492f-498f-d744-75445a908148"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 27,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7,\n        \"min\": 1,\n        \"max\": 27,\n        \"num_unique_values\": 27,\n        \"samples\": [\n          9,\n          14,\n          10\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"query\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 27,\n        \"samples\": [\n          \"How does the boosting method work to minimize total error in a prediction model?\",\n          \"What is the purpose of using Tensor Processing Units (TPUs) in deep learning?\",\n          \"What is the structure and purpose of a database table in managing data?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prompt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 27,\n        \"samples\": [\n          \"Context information is below.\\n---------------------\\nSource 1:\\n-----\\nrepresents an error or gradient. This breakdown helps us manage and minimize the total error more effectively. The boosting method uses a model to predict each piece. We iteratively refine our final prediction by summing up all these predicted errors:   where m_i(x) are the models predicting each error piece.   In practice  when implementing the boosting method  we use the following Taylor expansion to approximate the loss function:   We can illustrate the boosting algorithm with the following example:   Just as a supermarket sells bread at varying discounts based on freshness to maximize sales  similarly  the boosting method handles the residuals of a loss function. Earlier residuals (lower-order terms) significantly reduce the loss value  while later residuals (higher-order terms) have a diminishing effect  akin to the decreasing value of less fresh bread. This process continues until no further reduction in loss can be achieved.   The boosting algorithm accumulates these contributions to minimize the total loss value  refining the models predictions iteratively. Each iteration builds on the previous one  incorporating the residuals to improve overall prediction accuracy.   An Intuitive Example of BoostingLets walk through a straightforward Boosting example using linear regression.   Imagine we predict y = 7 given x = 2. We now create a model that makes this prediction through iterative steps.   InitializationWe start with an initial prediction. For simplicity  lets assume our initial prediction is zero:   First IterationPerform Linear Regression: begin by fitting a simple linear regression model to our data point (x = 2  y = 7):Using x = 2 and y = 7  we solve for a and b:   Assume the model predicts p_1 = 4. The residual error e_1 is:   Update the Prediction: update the initial prediction with this new value:Second IterationFit Residuals: perform linear regression on the residual e_1:Using x = 2 and e_1 = 3  we solve for the new prediction p2:   Assume the model predicts p_2 = 2. The new residual e_2 is:   Update the Prediction: add this new value to our prediction:Third IterationFit Residuals: continue by fitting linear regression on the new residual e_2:Using x = 2 and e_2 =\\n-----\\n\\nSource 2:\\n-----\\nresidual error e_1 is:   Update the Prediction: update the initial prediction with this new value:Second IterationFit Residuals: perform linear regression on the residual e_1:Using x = 2 and e_1 = 3  we solve for the new prediction p2:   Assume the model predicts p_2 = 2. The new residual e_2 is:   Update the Prediction: add this new value to our prediction:Third IterationFit Residuals: continue by fitting linear regression on the new residual e_2:Using x = 2 and e_2 = 1  we solve for the new prediction p_3:   Assume the model predicts p_3=1. The new residual e_3 is:   Update the Prediction: add this final value to our prediction:This example illustrates the basic mechanism of boosting using linear regression. But in practice more complex models like decision trees are utilized to predict residuals  leading to techniques such as Gradient Boosting Trees.   Gradient Boosting TreesWhy Not Use Linear Regression in Boosting?In our previous example  we used linear regression to predict gradients in each boosting step to demonstrate the basic concept of boosting. However  linear regression is not suitable due to the orthogonality of error and prediction.   In linear regression  the error (residual) is orthogonal to the predictions  meaning the residuals are uncorrelated with the predicted values:   This approach doesnt capture complex error patterns. Because of this orthogonality  fitting a linear regression model to the residuals multiple times is the same as fitting it once to the original data. Therefore  using linear regression in an iterative boosting framework doesnt add extra value over a single linear regression model.   Why Use Tree Models in Boosting?Boosting is an ensemble algorithm  meaning the final prediction is obtained by combining the outputs from multiple models. Interaction and bagging efficiency are important to the production of highly accurate results. Tree models meet these requirements for several reasons:   Non-linearity and Accurate Gradient Prediction Tree models can capture non-linear relationships between features and the target variable  accurately predicting gradients.   Local Approximation Tree models split data into regions and fit simple models (like constants) within these regions. This local approximation can precisely capture the datas patterns.   Handling\\n-----\\n\\nSource 3:\\n-----\\nA Deep Dive into the Mechanisms of Boosting with Step-by-Step Examples  Leading to the Development of Boosting in Machine Learning   Boosting is a powerful machine learning technique widely used to improve the performance of predictive models. Its a key component in many winning models on platforms like Kaggle. But what makes boosting so effective? How does it work? This article will break down the boosting algorithm both mathematically and practically.   Well start with the basics  explaining the mathematical foundation of the boosting algorithm in simple terms. Youll see how boosting iteratively improves predictions by correcting errors from previous models. This process is crucial for mastering and effectively applying boosting.   Next  well move to hands-on implementation. Instead of pre-built Python packages  well write the boosting algorithm from scratch  using decision trees as base learners. This approach will help you understand how boosting works step by step.   Finally  well introduce XGBoost  a popular gradient-boosting implementation. Well explain how XGBoost fits into the general boosting framework and guide you through creating a raw XGBoost model.   By the end of this article  youll understand how boosting works and how to implement and customize it for your predictive modeling tasks.   How Does Boosting WorkImagine we have a model represented by the equation:   f(x) is our models prediction  and y is the actual value. Our goal is to make our model as accurate as possible by minimizing the total error  known as the loss function:   To minimize the loss function  we split it into many smaller pieces. The loss function can often be complex or have no explicit form  so we express it as a sum of smaller components:   Each piece represents an error or gradient. This breakdown helps us manage and minimize the total error more effectively. The boosting method uses a model to predict each piece. We iteratively refine our final prediction by summing up all these predicted errors:   where m_i(x) are the models predicting each error piece.   In practice  when implementing the boosting method  we use the following Taylor expansion to approximate the loss function:   We can illustrate the boosting algorithm with the following example:   Just as a supermarket sells bread at varying discounts based on freshness to maximize sales  similarly  the boosting method handles the residuals of a loss function.\\n-----\\n\\nSource 4:\\n-----\\n[2]  [3]]) y = np.array([0  0  3  -1]) # Initialize and fit the model model = GradientBoostingRegressor(n_estimators=100  learning_rate=0.5  max_depth=1  random_state=0) model.fit(X  y) # Predictions predictions = model.predict(X) print(Predictions:  predictions) # Plotting the results plt.figure(figsize=(10  6)) plt.scatter(X  y  color='red'  label='Actual data') plt.plot(X  predictions  color='blue'  label='Predicted data') plt.xlabel('X') plt.ylabel('y') plt.title('Boosting Gradient Tree Model') plt.legend() plt.show()Here is the output of the raw method:   Here is the output of the GradientBoostingRegressor method:   By comparing the raw boosting with the GradientBoostingRegressor from SKLEARN  we can better understand the inner workings of the boosting algorithm and how it iteratively improves the models performance.   General Framework and Mathematical FoundationsBased on the example in the previous section. we summarize the following general boosting procedure:   1. Initialization:   The initial model is typically a simple model  such as predicting the mean   of the target values.   2. Iterative Process:   For each iteration i  the following steps are performed:   Calculate errors:   The errors e_i represent the discrepancies between the actual target values y and the predictions from the previous model. The error function can be Mean Absolute Percentage Error (MAPE)  Mean Squared Error (MSE)  or others.   Fit Model to Errors:   Update the Model:   In addition  the predictions are updated by adding the new models predictions  scaled by a learning rate   to the previous models predictions.   We now investigate the logistics for the boosting steps above; this is related to minimizing a loss function L(y  f(x)) that measures the difference between the actual target values y and the models predictions f(x).   A loss function is used in machine learning to see how close a models predictions are to the real data. Think of it as a way to measure the error or badness of the model predictions. The lower the loss function value  the\\n-----\\n\\nSource 5:\\n-----\\nUpdate the Model:   In addition  the predictions are updated by adding the new models predictions  scaled by a learning rate   to the previous models predictions.   We now investigate the logistics for the boosting steps above; this is related to minimizing a loss function L(y  f(x)) that measures the difference between the actual target values y and the models predictions f(x).   A loss function is used in machine learning to see how close a models predictions are to the real data. Think of it as a way to measure the error or badness of the model predictions. The lower the loss function value  the better the model is performing. It helps to calculate the total error between the model and the sample data. The loss function can often be explicitly expressed as a math formula  such as linear and logistic regressions  but there might be no simple math form like a decision tree and neural networks.   The steps can be mathematically formalized as follows:   The initial model f_0(x) is chosen to minimize the loss function over the training data.   2. Gradient Descent on Errors: For each iteration i: Compute the Gradient and Hessian:   The gradient represents the direction of the steepest increase in the loss function. The Hessian provides information about the curvature of the loss function. Computing the gradient and Hessian is essential because we use them in building the decision tree model below.   Fit a Decision Tree:   In this step where we fit a Decision Tree  the tree model m_i(x) is trained to predict the gradient g_i with a regularization term that involves the Hessian h_i. Here  the objective function (i.e. the approximation of the loss function) combines the gradient and the Hessian to determine the optimal split and leaf in the decision tree. The formulation   ensures that the tree is trained to approximate the gradient and account for the curvature from the Hessian. Therefore  the tree model primarily predicts the gradient while being influenced by the Hessian to improve the robustness and stability of the model.   Regularization is used in the boosting method to prevent overfitting and ensure that the model generalizes well to new data. The regularization term (f) can include both L1 and L2 penalties:   where  and  are regularization parameters\\n-----\\n---------------------\\nGiven the context information and not prior knowledge, answer the query.\\nQuery: How does the boosting method work to minimize total error in a prediction model?\\nAnswer: \",\n          \"Context information is below.\\n---------------------\\nSource 1:\\n-----\\nthat could perform 8-bit multiply-and-adds on signed or unsigned integers. The 16-bit products were then collected in 4 MiB of 32-bit Accumulators below the matrix unit. Then there are other components like the activation pipeline that could perform activation functions on the resulting matrix.   For more details about the Google TPU that was released in 2017 read this very interesting paper where they discuss in detail the TPUs design and performance!   In-datacenter performance analysis of a tensor processing unit U+007C IEEE Conference Publication U+007C IEEE Xplore   TPU v2 and v3Improving upon the design of TPU v1 Google released the specifications of TPU v2 and v3 as well with some major changes:   Interconnect  A critical element of any chip design is the interconnect which decides how fast is the inter-chip communication. An on-device switch called Interconnect Router (see above figure) provides deadlock-free routing. It enables a 2D torus topology of interconnect.Memory  A major performance bottleneck in TPU v1 was the limited memory bandwidth of DRAM. This problem was somewhat solved using the HBM (High Bandwidth Memory) DRAM in TPU v2. It offers 20 times the bandwidth of TPU v1 by using an interposer substrate that connects the TPU v2 chip via thirty-two 128-bit buses to 4-stacks of DRAM chips.Multiple smaller MXU units per chip  While TPUv1 featured a MXU of the size 256x256  it was reduced to 128x128 in TPUv2 onwards and has multiple MXUs per chip. Larger MXUs require more memory bandwidth for optimal chip utilization. Google analyzed that convolutional model utilization ranged between 37%-48% for 128x128 MXUs  which was 1.6x of a single 256x256 MXU (22%-30%). The reason that Google has come up with this is that some convolutions are naturally smaller than 256x256  which leaves parts of the MXU unused.For more details regarding Google TPU v2 and v3:   A Domain Specific Supercomputer for Training Deep Neural Networks U+007C ACM   AI and Memory WallThe amount of computing needed to train modern deep learning models and perform inference using\\n-----\\n\\nSource 2:\\n-----\\n# Training on TPU with TensorFlow<Tip>If you don't need long explanations and just want TPU code samples to get started with, check out [our TPU example notebook!](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/tpu_training-tf.ipynb)</Tip>### What is a TPU?A TPU is a **Tensor Processing Unit.** They are hardware designed by Google, which are used to greatly speed up the tensor computations within neural networks, much like GPUs. They can be used for both network training and inference. They are generally accessed through Google\\u2019s cloud services, but small TPUs can also be accessed directly for free through Google Colab and Kaggle Kernels.Because [all TensorFlow models in \\ud83e\\udd17 Transformers are Keras models](https://huggingface.co/blog/tensorflow-philosophy), most of the methods in this document are generally applicable to TPU training for any Keras model! However, there are a few points that are specific to the HuggingFace ecosystem (hug-o-system?) of Transformers and Datasets, and we\\u2019ll make sure to flag them up when we get to them.### What kinds of TPU are available?New users are often very confused by the range of TPUs, and the different ways to access them. The first key distinction to understand is the difference between **TPU Nodes** and **TPU VMs.**When you use a **TPU Node**, you are effectively indirectly accessing a remote TPU. You will need a separate VM, which will initialize your network and data pipeline and then forward them to the remote node. When you use a TPU on Google Colab, you are accessing it in the **TPU Node** style.Using TPU Nodes can have some quite unexpected behaviour for people who aren\\u2019t used to them! In particular, because the TPU is located on a physically different system to the machine you\\u2019re running your Python code on, your data cannot be local to your machine - any data pipeline that loads from your machine\\u2019s internal storage will totally fail! Instead, data must be stored in Google Cloud Storage where your data pipeline can still access it, even when the pipeline is running on the remote TPU node.<Tip>If you can fit all your data in memory as `np.ndarray` or `tf.Tensor`, then you can `fit()`\\n-----\\n\\nSource 3:\\n-----\\nnumber of rows and columns of the IFMAP and FILTER respectively. T is the temporal dimension which in the case of the output stationary represents the convolution window size.   As described by the figure above  we can conclude that the number of cycles for the systolic array to perform a matrix multiplication is:   Obviously  in the real world  we do not have unlimited MACs. In that case  we divide the workload by the number of available MAC units and therefore get the following expression for timing:   Here  we assume that R and C are the actual dimensions of the systolic array and Sr and Sc are the required dimensions. To decrease this time  we can increase the number of MAC units  a process we can call scaling up. Another approach is to have multiple MAC array units that perform the compute in parallel  which can be called scaling out. This further reduces the time needed to complete the operation.   A look inside Google TPUOriginsBack in 2013  a projection at Google showed that if people searched using voice even for 3 minutes a day  it would result in doubling the computing demand of Googles datacenters. Speech recognition models that used DNN were very expensive to perform inference using traditional CPUs. Therefore  they started working on a custom ASIC (application-specific integrated circuit) that would perform inference efficiently. The goal was 10x performance over GPUs. The outcome of this effort was the Google Tensor Processing Unit. Google TPU was based on the systolic array architecture.   TPU v1As you are now aware systolic array-based AI accelerators are composed of MAC units. Googles original TPU implementation consisted of 256x256 MAC units (see Matrix Multiply Unit in the figure above) that could perform 8-bit multiply-and-adds on signed or unsigned integers. The 16-bit products were then collected in 4 MiB of 32-bit Accumulators below the matrix unit. Then there are other components like the activation pipeline that could perform activation functions on the resulting matrix.   For more details about the Google TPU that was released in 2017 read this very interesting paper where they discuss in detail the TPUs design and performance!   In-datacenter performance analysis of a tensor processing unit U+007C IEEE Conference Publication U+007C IEEE Xplore   TPU v2 and\\n-----\\n\\nSource 4:\\n-----\\nstyle.Using TPU Nodes can have some quite unexpected behaviour for people who aren\\u2019t used to them! In particular, because the TPU is located on a physically different system to the machine you\\u2019re running your Python code on, your data cannot be local to your machine - any data pipeline that loads from your machine\\u2019s internal storage will totally fail! Instead, data must be stored in Google Cloud Storage where your data pipeline can still access it, even when the pipeline is running on the remote TPU node.<Tip>If you can fit all your data in memory as `np.ndarray` or `tf.Tensor`, then you can `fit()` on that data even when using Colab or a TPU Node, without needing to upload it to Google Cloud Storage.</Tip><Tip>**\\ud83e\\udd17Specific Hugging Face Tip\\ud83e\\udd17:** The methods `Dataset.to_tf_dataset()` and its higher-level wrapper `model.prepare_tf_dataset()` , which you will see throughout our TF code examples, will both fail on a TPU Node. The reason for this is that even though they create a `tf.data.Dataset` it is not a \\u201cpure\\u201d `tf.data` pipeline and uses `tf.numpy_function` or `Dataset.from_generator()` to stream data from the underlying HuggingFace `Dataset`. This HuggingFace `Dataset` is backed by data that is on a local disc and which the remote TPU Node will not be able to read.</Tip>The second way to access a TPU is via a **TPU VM.** When using a TPU VM, you connect directly to the machine that the TPU is attached to, much like training on a GPU VM. TPU VMs are generally easier to work with, particularly when it comes to your data pipeline. All of the above warnings do not apply to TPU VMs!This is an opinionated document, so here\\u2019s our opinion: **Avoid using TPU Node if possible.** It is more confusing and more difficult to debug than TPU VMs. It is also likely to be unsupported in future - Google\\u2019s latest TPU, TPUv4, can only be accessed as a TPU VM, which suggests that TPU Nodes are increasingly going to become a \\u201clegacy\\u201d access method. However, we understand that the only free TPU access is on Colab and Kaggle Kernels, which uses TPU Node - so we\\u2019ll try to\\n-----\\n\\nSource 5:\\n-----\\nBajwa  R.   & Yoon  D. H. (2017  June). In-datacenter performance analysis of a tensor processing unit. In Proceedings of the 44th annual international symposium on computer architecture (pp. 112).Jouppi  N. P.  Yoon  D. H.  Kurian  G.  Li  S.  Patil  N.  Laudon  J.   & Patterson  D. (2020). A domain-specific supercomputer for training deep neural networks. Communications of the ACM  63(7)  6778.Gholami  A.  Yao  Z.  Kim  S.  Hooper  C.  Mahoney  M. W.  & Keutzer  K. (2024). AI and memory wall. IEEE Micro.Samajdar  A.  Joseph  J. M.  Zhu  Y.  Whatmough  P.  Mattina  M.  & Krishna  T. (2020  August). A systematic methodology for characterizing scalability of dnn accelerators using scale-sim. In 2020 IEEE International Symposium on Performance Analysis of Systems and Software (ISPASS) (pp. 5868). IEEE.\\n-----\\n---------------------\\nGiven the context information and not prior knowledge, answer the query.\\nQuery: What is the purpose of using Tensor Processing Units (TPUs) in deep learning?\\nAnswer: \",\n          \"Context information is below.\\n---------------------\\nSource 1:\\n-----\\n\\\"State\\\" NVARCHAR(40),     \\\"Country\\\" NVARCHAR(40),     \\\"PostalCode\\\" NVARCHAR(10),     \\\"Phone\\\" NVARCHAR(24),     \\\"Fax\\\" NVARCHAR(24),     \\\"Email\\\" NVARCHAR(60),     PRIMARY KEY (\\\"EmployeeId\\\"),     FOREIGN KEY(\\\"ReportsTo\\\") REFERENCES \\\"Employee\\\" (\\\"EmployeeId\\\")    )        /*    3 rows from Employee table:    EmployeeIdLastNameFirstNameTitleReportsToBirthDateHireDateAddressCityStateCountryPostalCodePhoneFaxEmail    1AdamsAndrewGeneral ManagerNone1962-02-18 00:00:002002-08-14 00:00:0011120 Jasper Ave NWEdmontonABCanadaT5K 2N1+1 (780) 428-9482+1 (780) 428-3457andrew@chinookcorp.com    2EdwardsNancySales Manager11958-12-08 00:00:002002-05-01 00:00:00825 8 Ave SWCalgaryABCanadaT2P 2T3+1 (403) 262-3443+1 (403) 262-3322nancy@chinookcorp.com    3PeacockJaneSales Support Agent21973-08-29 00:00:002002-04-01 00:00:001111 6 Ave SWCalgaryABCanadaT2P 5M5+1 (403) 262-3443+1 (403) 262-6712jane@chinookcorp.com    */            CREATE TABLE \\\"Genre\\\" (    \\\"GenreId\\\" INTEGER NOT NULL,     \\\"Name\\\" NVARCHAR(120),     PRIMARY KEY (\\\"GenreId\\\")    )        /*    3 rows from Genre table:    GenreIdName    1Rock    2Jazz    3Metal    */\\n-----\\n\\nSource 2:\\n-----\\nvideo file    */            CREATE TABLE \\\"Playlist\\\" (    \\\"PlaylistId\\\" INTEGER NOT NULL,     \\\"Name\\\" NVARCHAR(120),     PRIMARY KEY (\\\"PlaylistId\\\")    )        /*    3 rows from Playlist table:    PlaylistIdName    1Music    2Movies    3TV Shows    */            CREATE TABLE \\\"PlaylistTrack\\\" (    \\\"PlaylistId\\\" INTEGER NOT NULL,     \\\"TrackId\\\" INTEGER NOT NULL,     PRIMARY KEY (\\\"PlaylistId\\\", \\\"TrackId\\\"),     FOREIGN KEY(\\\"TrackId\\\") REFERENCES \\\"Track\\\" (\\\"TrackId\\\"),     FOREIGN KEY(\\\"PlaylistId\\\") REFERENCES \\\"Playlist\\\" (\\\"PlaylistId\\\")    )        /*    3 rows from PlaylistTrack table:    PlaylistIdTrackId    13402    13389    13390    */            CREATE TABLE \\\"Track\\\" (    \\\"TrackId\\\" INTEGER NOT NULL,     \\\"Name\\\" NVARCHAR(200) NOT NULL,     \\\"AlbumId\\\" INTEGER,     \\\"MediaTypeId\\\" INTEGER NOT NULL,     \\\"GenreId\\\" INTEGER,     \\\"Composer\\\" NVARCHAR(220),     \\\"Milliseconds\\\" INTEGER NOT NULL,     \\\"Bytes\\\" INTEGER,     \\\"UnitPrice\\\" NUMERIC(10, 2) NOT NULL,     PRIMARY KEY (\\\"TrackId\\\"),     FOREIGN KEY(\\\"MediaTypeId\\\") REFERENCES \\\"MediaType\\\" (\\\"MediaTypeId\\\"),     FOREIGN KEY(\\\"GenreId\\\") REFERENCES \\\"Genre\\\" (\\\"GenreId\\\"),     FOREIGN KEY(\\\"AlbumId\\\") REFERENCES \\\"Album\\\" (\\\"AlbumId\\\")    )        /*    3 rows from Track table:    TrackIdNameAlbumIdMediaTypeIdGenreIdComposerMillisecondsBytesUnitPrice    1For Those About To Rock (We\\n-----\\n\\nSource 3:\\n-----\\nthe user question. In this case, we might think to simplify our model's job by grouping the tables together. We'll just ask the model to choose between categories \\\"Music\\\" and \\\"Business\\\", and then take care of selecting all the relevant tables from there:```pythonsystem = \\\"\\\"\\\"Return the names of any SQL tables that are relevant to the user question.The tables are:MusicBusiness\\\"\\\"\\\"prompt = ChatPromptTemplate.from_messages(    [        (\\\"system\\\", system),        (\\\"human\\\", \\\"{input}\\\"),    ])category_chain = prompt | llm_with_tools | output_parsercategory_chain.invoke({\\\"input\\\": \\\"What are all the genres of Alanis Morisette songs\\\"})```    [Table(name='Music'), Table(name='Business')]```pythonfrom typing import Listdef get_tables(categories: List[Table]) -> List[str]:    tables = []    for category in categories:        if category.name == \\\"Music\\\":            tables.extend(                [                    \\\"Album\\\",                    \\\"Artist\\\",                    \\\"Genre\\\",                    \\\"MediaType\\\",                    \\\"Playlist\\\",                    \\\"PlaylistTrack\\\",                    \\\"Track\\\",                ]            )        elif category.name == \\\"Business\\\":            tables.extend([\\\"Customer\\\", \\\"Employee\\\", \\\"Invoice\\\", \\\"InvoiceLine\\\"])    return tablestable_chain = category_chain | get_tablestable_chain.invoke({\\\"input\\\": \\\"What are all the\\n-----\\n\\nSource 4:\\n-----\\nand feed this into an output parser to reconstruct the object from the model's response.```{=mdx}import ChatModelTabs from \\\"@theme/ChatModelTabs\\\";<ChatModelTabs customVarName=\\\"llm\\\" />``````python# | output: false# | echo: falsefrom langchain_openai import ChatOpenAIllm = ChatOpenAI()``````pythonfrom langchain_core.output_parsers.openai_tools import PydanticToolsParserfrom langchain_core.prompts import ChatPromptTemplatefrom langchain_core.pydantic_v1 import BaseModel, Fieldclass Table(BaseModel):    \\\"\\\"\\\"Table in SQL database.\\\"\\\"\\\"    name: str = Field(description=\\\"Name of table in SQL database.\\\")table_names = \\\"\\\\n\\\".join(db.get_usable_table_names())system = f\\\"\\\"\\\"Return the names of ALL the SQL tables that MIGHT be relevant to the user question. \\\\The tables are:{table_names}Remember to include ALL POTENTIALLY RELEVANT tables, even if you're not sure that they're needed.\\\"\\\"\\\"prompt = ChatPromptTemplate.from_messages(    [        (\\\"system\\\", system),        (\\\"human\\\", \\\"{input}\\\"),    ])llm_with_tools = llm.bind_tools([Table])output_parser = PydanticToolsParser(tools=[Table])table_chain = prompt | llm_with_tools | output_parsertable_chain.invoke({\\\"input\\\": \\\"What are all the genres of Alanis Morisette songs\\\"})```    [Table(name='Genre')]This works pretty well! Except, as we'll see below, we actually need a few other tables as well. This would be pretty difficult for the model to know based just on the user question. In this case, we might think to simplify our model's job by grouping the tables together. We'll just ask the model to choose between categories \\\"Music\\\" and \\\"Business\\\", and then take care of selecting all the relevant tables from there:```pythonsystem = \\\"\\\"\\\"Return the names of any SQL tables that are relevant to the user question.The tables are:MusicBusiness\\\"\\\"\\\"prompt = ChatPromptTemplate.from_messages(    [        (\\\"system\\\", system),        (\\\"human\\\", \\\"{input}\\\"),    ])category_chain = prompt |\\n-----\\n\\nSource 5:\\n-----\\n00:00:00Ulleva\\u030alsveien 14OsloNoneNorway01713.96    382021-01-03 00:00:00Gre\\u0301trystraat 63BrusselsNoneBelgium10005.94    */            CREATE TABLE \\\"InvoiceLine\\\" (    \\\"InvoiceLineId\\\" INTEGER NOT NULL,     \\\"InvoiceId\\\" INTEGER NOT NULL,     \\\"TrackId\\\" INTEGER NOT NULL,     \\\"UnitPrice\\\" NUMERIC(10, 2) NOT NULL,     \\\"Quantity\\\" INTEGER NOT NULL,     PRIMARY KEY (\\\"InvoiceLineId\\\"),     FOREIGN KEY(\\\"TrackId\\\") REFERENCES \\\"Track\\\" (\\\"TrackId\\\"),     FOREIGN KEY(\\\"InvoiceId\\\") REFERENCES \\\"Invoice\\\" (\\\"InvoiceId\\\")    )        /*    3 rows from InvoiceLine table:    InvoiceLineIdInvoiceIdTrackIdUnitPriceQuantity    1120.991    2140.991    3260.991    */            CREATE TABLE \\\"MediaType\\\" (    \\\"MediaTypeId\\\" INTEGER NOT NULL,     \\\"Name\\\" NVARCHAR(120),     PRIMARY KEY (\\\"MediaTypeId\\\")    )        /*    3 rows from MediaType table:    MediaTypeIdName    1MPEG audio file    2Protected AAC audio file    3Protected MPEG-4 video file    */            CREATE TABLE \\\"Playlist\\\" (    \\\"PlaylistId\\\" INTEGER NOT NULL,     \\\"Name\\\" NVARCHAR(120),     PRIMARY KEY (\\\"PlaylistId\\\")    )        /*    3 rows from Playlist table:    PlaylistIdName    1Music    2Movies    3TV Shows    */            CREATE TABLE \\\"PlaylistTrack\\\" (\\n-----\\n---------------------\\nGiven the context information and not prior knowledge, answer the query.\\nQuery: What is the structure and purpose of a database table in managing data?\\nAnswer: \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"response\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 27,\n        \"samples\": [\n          \"The boosting method works to minimize total error in a prediction model through an iterative process that focuses on correcting the errors made by previous models. Here\\u2019s how it operates:\\n\\n1. **Initialization**: The process begins with an initial model, which is typically a simple one that might predict the mean of the target values.\\n\\n2. **Iterative Refinement**: In each iteration, boosting calculates the prediction errors (residuals) from the current model. These residuals represent the discrepancies between the actual target values and the predictions made by the model.\\n\\n3. **Error Prediction**: A new model (often a decision tree) is then fitted specifically to these residuals. This model aims to predict the errors made by the previous predictions.\\n\\n4. **Gradient and Hessian**: The boosting algorithm uses the gradient of the loss function to determine the direction of improvement. The gradient indicates the direction of steepest ascent in the loss function, while the Hessian provides curvature information. These metrics help to train the new model effectively, ensuring it focuses on the most significant errors.\\n\\n5. **Model Update**: The predictions from the new model are scaled by a learning rate and added to the previous model\\u2019s predictions. This step updates the overall prediction by incorporating the newly learned information.\\n\\n6. **Repeat**: The process of calculating residuals, fitting a new model, and updating predictions continues for a specified number of iterations or until the loss converges to a satisfactory level.\\n\\nBy iteratively correcting the model\\u2019s predictions based on the errors of prior models and using mathematical foundations like the gradient and Hessian, boosting effectively minimizes the total error in the prediction model, leading to improved accuracy and performance.\",\n          \"The purpose of using Tensor Processing Units (TPUs) in deep learning is to accelerate tensor computations, which are fundamental to the training and inference of neural networks. TPUs are specialized hardware designed by Google to provide significantly improved performance over traditional CPUs and even GPUs for deep learning tasks. They enhance the efficiency of operations such as matrix multiplications, enabling faster processing of large models and datasets. TPUs leverage architectures like systolic arrays and advanced memory bandwidth features to optimize deep learning workloads, making them particularly suitable for applications involving deep neural networks, such as speech recognition and image classification. Overall, TPUs help meet the growing computational demands of modern AI applications by delivering higher throughput and efficiency.\",\n          \"The structure of a database table typically consists of rows and columns, where each column represents a specific attribute or field of the data, and each row corresponds to a unique record or entry in the table. \\n\\nKey components of a database table include:\\n\\n1. **Columns (Fields)**: Each column has a defined data type (e.g., INTEGER, NVARCHAR, DATETIME) and represents a specific attribute of the data being stored. For example, in an \\\"Employee\\\" table, columns might include \\\"EmployeeId,\\\" \\\"FirstName,\\\" \\\"LastName,\\\" \\\"Title,\\\" and \\\"Email.\\\"\\n\\n2. **Rows (Records)**: Each row in the table corresponds to a single record, containing data for each field defined by the columns. For instance, a row in the \\\"Employee\\\" table would contain data for one employee, including their ID, name, title, and contact information.\\n\\n3. **Primary Key**: This is a unique identifier for each record in the table, ensuring that no two rows can have the same value for this field. For example, \\\"EmployeeId\\\" might serve as the primary key in an \\\"Employee\\\" table.\\n\\n4. **Foreign Key**: This establishes relationships between tables, linking records in one table to records in another. For example, if an \\\"Invoice\\\" table includes a \\\"CustomerId\\\" foreign key, it references the unique identifier in the \\\"Customer\\\" table, thereby associating invoices with specific customers.\\n\\nThe purpose of a database table in managing data is to organize and store related data efficiently, making it easy to retrieve, manipulate, and analyze. This structured approach allows for effective querying, ensuring that users can obtain relevant information quickly and accurately based on the relationships and constraints defined within the database schema. \\n\\nFor example, in a relational database, tables like \\\"Employee,\\\" \\\"Genre,\\\" and \\\"Invoice\\\" work together, with foreign keys linking them, to maintain data integrity and provide meaningful insights across various datasets.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"domain_expert_label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Bad\",\n          \"Good\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"domain_expert_critique\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 27,\n        \"samples\": [\n          \"The explanation provides a basic overview of the iterative process used in boosting, including error calculation and model updates. However, the answer feels generic and somewhat repetitive, lacking a deeper dive into key elements like regularization techniques or the specific role of the Hessian in refining predictions. While it covers the main steps, it does not fully capture the complexity and nuance of boosting as described in the context.\",\n          \"The response accurately details that TPUs are specialized hardware designed to accelerate tensor computations, essential for training and inference in deep learning. It compares TPUs with other hardware like CPUs and GPUs and highlights their advantages, fully addressing the query.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-3f7094ac-055f-4f05-a61f-f04670d7ff6f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>query</th>\n",
              "      <th>prompt</th>\n",
              "      <th>response</th>\n",
              "      <th>domain_expert_label</th>\n",
              "      <th>domain_expert_critique</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>What are some strategies to improve the perfor...</td>\n",
              "      <td>Context information is below.\\n---------------...</td>\n",
              "      <td>To improve the performance of a Retrieval-Augm...</td>\n",
              "      <td>Good</td>\n",
              "      <td>The response comprehensively lists multiple st...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>What is dequantization and how does it relate ...</td>\n",
              "      <td>Context information is below.\\n---------------...</td>\n",
              "      <td>Dequantization is the process of converting lo...</td>\n",
              "      <td>Good</td>\n",
              "      <td>The answer accurately defines dequantization a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>How can you utilize a GPU to speed up the trai...</td>\n",
              "      <td>Context information is below.\\n---------------...</td>\n",
              "      <td>To utilize a GPU to speed up the training proc...</td>\n",
              "      <td>Good</td>\n",
              "      <td>The response provides a detailed, multi-facete...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>What are the specific characters used in Markd...</td>\n",
              "      <td>Context information is below.\\n---------------...</td>\n",
              "      <td>The specific characters used in Markdown for s...</td>\n",
              "      <td>Bad</td>\n",
              "      <td>The response is overly generic and lacks speci...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>How can you use the Transformers library to pe...</td>\n",
              "      <td>Context information is below.\\n---------------...</td>\n",
              "      <td>To use the Transformers library for inference ...</td>\n",
              "      <td>Good</td>\n",
              "      <td>The answer is well-detailed and practical, off...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>What techniques can be used to finetune large ...</td>\n",
              "      <td>Context information is below.\\n---------------...</td>\n",
              "      <td>To fine-tune large AI models on a single GPU, ...</td>\n",
              "      <td>Good</td>\n",
              "      <td>The response effectively outlines a range of t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>What are some strategies to handle variable-si...</td>\n",
              "      <td>Context information is below.\\n---------------...</td>\n",
              "      <td>To handle variable-sized inputs efficiently in...</td>\n",
              "      <td>Good</td>\n",
              "      <td>The answer lists several effective strategies ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>What are the main challenges addressed by Retr...</td>\n",
              "      <td>Context information is below.\\n---------------...</td>\n",
              "      <td>Retrieval-Augmented Generation (RAG) addresses...</td>\n",
              "      <td>Bad</td>\n",
              "      <td>While the response identifies a few challenges...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>How does the boosting method work to minimize ...</td>\n",
              "      <td>Context information is below.\\n---------------...</td>\n",
              "      <td>The boosting method works to minimize total er...</td>\n",
              "      <td>Bad</td>\n",
              "      <td>The explanation provides a basic overview of t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>What is the structure and purpose of a databas...</td>\n",
              "      <td>Context information is below.\\n---------------...</td>\n",
              "      <td>The structure of a database table typically co...</td>\n",
              "      <td>Bad</td>\n",
              "      <td>The response outlines the basic components of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>11</td>\n",
              "      <td>How does CodexGraph facilitate the interaction...</td>\n",
              "      <td>Context information is below.\\n---------------...</td>\n",
              "      <td>CodexGraph facilitates the interaction between...</td>\n",
              "      <td>Good</td>\n",
              "      <td>The response clearly explains that CodexGraph ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>12</td>\n",
              "      <td>What are the capabilities of the Nougat model ...</td>\n",
              "      <td>Context information is below.\\n---------------...</td>\n",
              "      <td>The Nougat model supports both training and in...</td>\n",
              "      <td>Bad</td>\n",
              "      <td>The response is overly generic and lacks speci...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>13</td>\n",
              "      <td>How can you restructure JSON data to be loaded...</td>\n",
              "      <td>Context information is below.\\n---------------...</td>\n",
              "      <td>To restructure JSON data for correct loading i...</td>\n",
              "      <td>Good</td>\n",
              "      <td>The answer provides a clear, step-by-step appr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>14</td>\n",
              "      <td>What is the purpose of using Tensor Processing...</td>\n",
              "      <td>Context information is below.\\n---------------...</td>\n",
              "      <td>The purpose of using Tensor Processing Units (...</td>\n",
              "      <td>Good</td>\n",
              "      <td>The response accurately details that TPUs are ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>15</td>\n",
              "      <td>What is the purpose of using the forward metho...</td>\n",
              "      <td>Context information is below.\\n---------------...</td>\n",
              "      <td>The purpose of using the `forward` method in `...</td>\n",
              "      <td>Bad</td>\n",
              "      <td>The response is overly simplistic, stating onl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>16</td>\n",
              "      <td>What is the role of temperature in the distill...</td>\n",
              "      <td>Context information is below.\\n---------------...</td>\n",
              "      <td>In the distillation process of neural networks...</td>\n",
              "      <td>Good</td>\n",
              "      <td>The answer thoroughly explains how temperature...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>17</td>\n",
              "      <td>What steps can be taken to find a suitable adv...</td>\n",
              "      <td>Context information is below.\\n---------------...</td>\n",
              "      <td>To find a suitable advisor for research in a s...</td>\n",
              "      <td>Good</td>\n",
              "      <td>The response provides a comprehensive list of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>18</td>\n",
              "      <td>What distinguishes reinforcement learning from...</td>\n",
              "      <td>Context information is below.\\n---------------...</td>\n",
              "      <td>Reinforcement learning (RL) is distinguished f...</td>\n",
              "      <td>Good</td>\n",
              "      <td>The answer effectively distinguishes reinforce...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>19</td>\n",
              "      <td>What are the main stages involved in the Graph...</td>\n",
              "      <td>Context information is below.\\n---------------...</td>\n",
              "      <td>The main stages involved in the GraphRAG workf...</td>\n",
              "      <td>Bad</td>\n",
              "      <td>Although the response correctly lists the thre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>20</td>\n",
              "      <td>How can you ensure that audio samples in a dat...</td>\n",
              "      <td>Context information is below.\\n---------------...</td>\n",
              "      <td>To ensure that audio samples in a dataset have...</td>\n",
              "      <td>Good</td>\n",
              "      <td>The response provides a clear and practical ex...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>21</td>\n",
              "      <td>What are some advantages of using OpenRouter f...</td>\n",
              "      <td>Context information is below.\\n---------------...</td>\n",
              "      <td>Some advantages of using OpenRouter for AI mod...</td>\n",
              "      <td>Good</td>\n",
              "      <td>The response provides a clear and comprehensiv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>22</td>\n",
              "      <td>What are the potential benefits of using AI to...</td>\n",
              "      <td>Context information is below.\\n---------------...</td>\n",
              "      <td>The potential benefits of using AI tools to sa...</td>\n",
              "      <td>Good</td>\n",
              "      <td>The answer effectively outlines multiple benef...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>23</td>\n",
              "      <td>What are the benefits of pruning in neural net...</td>\n",
              "      <td>Context information is below.\\n---------------...</td>\n",
              "      <td>Pruning in neural networks offers several bene...</td>\n",
              "      <td>Good</td>\n",
              "      <td>This response directly addresses the query by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>24</td>\n",
              "      <td>What is the role of output parsers in processi...</td>\n",
              "      <td>Context information is below.\\n---------------...</td>\n",
              "      <td>The provided context does not explicitly menti...</td>\n",
              "      <td>Bad</td>\n",
              "      <td>The answer begins by noting that the provided ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>25</td>\n",
              "      <td>What optimization technique is recommended for...</td>\n",
              "      <td>Context information is below.\\n---------------...</td>\n",
              "      <td>The provided excerpts do not include specific ...</td>\n",
              "      <td>Bad</td>\n",
              "      <td>The response simply states that the context do...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>26</td>\n",
              "      <td>What are Text-Attributed Graphs (TAGs) and how...</td>\n",
              "      <td>Context information is below.\\n---------------...</td>\n",
              "      <td>Text-Attributed Graphs (TAGs) are a type of gr...</td>\n",
              "      <td>Good</td>\n",
              "      <td>The answer clearly explains that Text-Attribut...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>27</td>\n",
              "      <td>How do image labeling services contribute to t...</td>\n",
              "      <td>Context information is below.\\n---------------...</td>\n",
              "      <td>Image labeling services play a crucial role in...</td>\n",
              "      <td>Good</td>\n",
              "      <td>The response thoroughly explains the role of i...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3f7094ac-055f-4f05-a61f-f04670d7ff6f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3f7094ac-055f-4f05-a61f-f04670d7ff6f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3f7094ac-055f-4f05-a61f-f04670d7ff6f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7b586823-4402-4d1d-9dad-86150b72b1c5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7b586823-4402-4d1d-9dad-86150b72b1c5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7b586823-4402-4d1d-9dad-86150b72b1c5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_ad38fb8c-f33d-4b9f-bc16-99cc5ddb5bd4\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_ad38fb8c-f33d-4b9f-bc16-99cc5ddb5bd4 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "    id                                              query  \\\n",
              "0    1  What are some strategies to improve the perfor...   \n",
              "1    2  What is dequantization and how does it relate ...   \n",
              "2    3  How can you utilize a GPU to speed up the trai...   \n",
              "3    4  What are the specific characters used in Markd...   \n",
              "4    5  How can you use the Transformers library to pe...   \n",
              "5    6  What techniques can be used to finetune large ...   \n",
              "6    7  What are some strategies to handle variable-si...   \n",
              "7    8  What are the main challenges addressed by Retr...   \n",
              "8    9  How does the boosting method work to minimize ...   \n",
              "9   10  What is the structure and purpose of a databas...   \n",
              "10  11  How does CodexGraph facilitate the interaction...   \n",
              "11  12  What are the capabilities of the Nougat model ...   \n",
              "12  13  How can you restructure JSON data to be loaded...   \n",
              "13  14  What is the purpose of using Tensor Processing...   \n",
              "14  15  What is the purpose of using the forward metho...   \n",
              "15  16  What is the role of temperature in the distill...   \n",
              "16  17  What steps can be taken to find a suitable adv...   \n",
              "17  18  What distinguishes reinforcement learning from...   \n",
              "18  19  What are the main stages involved in the Graph...   \n",
              "19  20  How can you ensure that audio samples in a dat...   \n",
              "20  21  What are some advantages of using OpenRouter f...   \n",
              "21  22  What are the potential benefits of using AI to...   \n",
              "22  23  What are the benefits of pruning in neural net...   \n",
              "23  24  What is the role of output parsers in processi...   \n",
              "24  25  What optimization technique is recommended for...   \n",
              "25  26  What are Text-Attributed Graphs (TAGs) and how...   \n",
              "26  27  How do image labeling services contribute to t...   \n",
              "\n",
              "                                               prompt  \\\n",
              "0   Context information is below.\\n---------------...   \n",
              "1   Context information is below.\\n---------------...   \n",
              "2   Context information is below.\\n---------------...   \n",
              "3   Context information is below.\\n---------------...   \n",
              "4   Context information is below.\\n---------------...   \n",
              "5   Context information is below.\\n---------------...   \n",
              "6   Context information is below.\\n---------------...   \n",
              "7   Context information is below.\\n---------------...   \n",
              "8   Context information is below.\\n---------------...   \n",
              "9   Context information is below.\\n---------------...   \n",
              "10  Context information is below.\\n---------------...   \n",
              "11  Context information is below.\\n---------------...   \n",
              "12  Context information is below.\\n---------------...   \n",
              "13  Context information is below.\\n---------------...   \n",
              "14  Context information is below.\\n---------------...   \n",
              "15  Context information is below.\\n---------------...   \n",
              "16  Context information is below.\\n---------------...   \n",
              "17  Context information is below.\\n---------------...   \n",
              "18  Context information is below.\\n---------------...   \n",
              "19  Context information is below.\\n---------------...   \n",
              "20  Context information is below.\\n---------------...   \n",
              "21  Context information is below.\\n---------------...   \n",
              "22  Context information is below.\\n---------------...   \n",
              "23  Context information is below.\\n---------------...   \n",
              "24  Context information is below.\\n---------------...   \n",
              "25  Context information is below.\\n---------------...   \n",
              "26  Context information is below.\\n---------------...   \n",
              "\n",
              "                                             response domain_expert_label  \\\n",
              "0   To improve the performance of a Retrieval-Augm...                Good   \n",
              "1   Dequantization is the process of converting lo...                Good   \n",
              "2   To utilize a GPU to speed up the training proc...                Good   \n",
              "3   The specific characters used in Markdown for s...                 Bad   \n",
              "4   To use the Transformers library for inference ...                Good   \n",
              "5   To fine-tune large AI models on a single GPU, ...                Good   \n",
              "6   To handle variable-sized inputs efficiently in...                Good   \n",
              "7   Retrieval-Augmented Generation (RAG) addresses...                 Bad   \n",
              "8   The boosting method works to minimize total er...                 Bad   \n",
              "9   The structure of a database table typically co...                 Bad   \n",
              "10  CodexGraph facilitates the interaction between...                Good   \n",
              "11  The Nougat model supports both training and in...                 Bad   \n",
              "12  To restructure JSON data for correct loading i...                Good   \n",
              "13  The purpose of using Tensor Processing Units (...                Good   \n",
              "14  The purpose of using the `forward` method in `...                 Bad   \n",
              "15  In the distillation process of neural networks...                Good   \n",
              "16  To find a suitable advisor for research in a s...                Good   \n",
              "17  Reinforcement learning (RL) is distinguished f...                Good   \n",
              "18  The main stages involved in the GraphRAG workf...                 Bad   \n",
              "19  To ensure that audio samples in a dataset have...                Good   \n",
              "20  Some advantages of using OpenRouter for AI mod...                Good   \n",
              "21  The potential benefits of using AI tools to sa...                Good   \n",
              "22  Pruning in neural networks offers several bene...                Good   \n",
              "23  The provided context does not explicitly menti...                 Bad   \n",
              "24  The provided excerpts do not include specific ...                 Bad   \n",
              "25  Text-Attributed Graphs (TAGs) are a type of gr...                Good   \n",
              "26  Image labeling services play a crucial role in...                Good   \n",
              "\n",
              "                               domain_expert_critique  \n",
              "0   The response comprehensively lists multiple st...  \n",
              "1   The answer accurately defines dequantization a...  \n",
              "2   The response provides a detailed, multi-facete...  \n",
              "3   The response is overly generic and lacks speci...  \n",
              "4   The answer is well-detailed and practical, off...  \n",
              "5   The response effectively outlines a range of t...  \n",
              "6   The answer lists several effective strategies ...  \n",
              "7   While the response identifies a few challenges...  \n",
              "8   The explanation provides a basic overview of t...  \n",
              "9   The response outlines the basic components of ...  \n",
              "10  The response clearly explains that CodexGraph ...  \n",
              "11  The response is overly generic and lacks speci...  \n",
              "12  The answer provides a clear, step-by-step appr...  \n",
              "13  The response accurately details that TPUs are ...  \n",
              "14  The response is overly simplistic, stating onl...  \n",
              "15  The answer thoroughly explains how temperature...  \n",
              "16  The response provides a comprehensive list of ...  \n",
              "17  The answer effectively distinguishes reinforce...  \n",
              "18  Although the response correctly lists the thre...  \n",
              "19  The response provides a clear and practical ex...  \n",
              "20  The response provides a clear and comprehensiv...  \n",
              "21  The answer effectively outlines multiple benef...  \n",
              "22  This response directly addresses the query by ...  \n",
              "23  The answer begins by noting that the provided ...  \n",
              "24  The response simply states that the context do...  \n",
              "25  The answer clearly explains that Text-Attribut...  \n",
              "26  The response thoroughly explains the role of i...  "
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# Load the merged dataset\n",
        "with open(\"rag_eval_dataset_with_labels.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    d_dataset = json.load(f)\n",
        "\n",
        "# Convert to pandas DataFrame\n",
        "df = pd.DataFrame(d_dataset)\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "lPR50XS-Vpkb",
        "outputId": "bd1d6c54-55f1-4462-e1fa-fb89be6110d4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>domain_expert_label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Good</th>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bad</th>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "domain_expert_label\n",
              "Good    18\n",
              "Bad      9\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Let's see how many \"Good\" and \"Bad\" annotations there are in the data\n",
        "label_counts = df[\"domain_expert_label\"].value_counts()\n",
        "label_counts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IC4b71hRNInX"
      },
      "source": [
        "# Now that we worked with the data a bit, let's craft the first prompt for the LLM-as-a-judge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--Syqcz7gnxl"
      },
      "source": [
        "We'll leverage the domain expert critiques for this!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AYhm18yDNlRy"
      },
      "outputs": [],
      "source": [
        "# First version of the LLM-as-a-judge-prompt\n",
        "\n",
        "judge_prompt = \"\"\"\n",
        "Your tasks is to evaluate pairs of input prompts and output responses according to the following criteria:\n",
        "\n",
        "1. Matches the Source – The response should align with provided sources.\n",
        "2. Covers Key Points – It should address the main aspects of the query.\n",
        "3. Clear & Concise – The response should be easy to understand.\n",
        "4. Relevant & Specific – It must be on-topic and provide useful details.\n",
        "5. Accurate Information – No errors or misleading claims.\n",
        "\n",
        "If the response meets these criteria well, label it \"Good\". If it has major issues, label it \"Bad\".\n",
        "Provide also a critique that explains the reasoning behing the assigned label (write at most 100 words for it).\n",
        "The critique should be written in a single line.\n",
        "\n",
        "Here's the input prompt to evaluate:\n",
        "-----\n",
        "{prompt}\n",
        "-----\n",
        "\n",
        "Here's the output response to evaluate:\n",
        "-----\n",
        "{response}\n",
        "-----\n",
        "\n",
        "Use this format for your response (but don't rewrite the \"-\" characters):\n",
        "-----\n",
        "Label: <good-or-bad>\n",
        "\n",
        "Critique: <critique>\n",
        "-----\n",
        "\"\"\".strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyknSsSW1rSD",
        "outputId": "008495e4-af7c-40fa-b3ea-ed2e8b73fbc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/27\n",
            "2/27\n",
            "3/27\n",
            "4/27\n",
            "5/27\n",
            "6/27\n",
            "7/27\n",
            "8/27\n",
            "9/27\n",
            "10/27\n",
            "11/27\n",
            "12/27\n",
            "13/27\n",
            "14/27\n",
            "15/27\n",
            "16/27\n",
            "17/27\n",
            "18/27\n",
            "19/27\n",
            "20/27\n",
            "21/27\n",
            "22/27\n",
            "23/27\n",
            "24/27\n",
            "25/27\n",
            "26/27\n",
            "27/27\n"
          ]
        }
      ],
      "source": [
        "# Here we use GPT-4o as the judge to write the labels and the critiques\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "\n",
        "def get_judge_response(judge_prompt, input_prompt, output_response):\n",
        "    \"\"\"\n",
        "    Uses the LLM to create a judge response based on aggregated critiques.\n",
        "    \"\"\"\n",
        "\n",
        "    formatted_prompt = judge_prompt.format(\n",
        "        prompt=input_prompt, response=output_response\n",
        "    )\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[{\"role\": \"user\", \"content\": formatted_prompt}],\n",
        "        temperature=0.7,\n",
        "    )\n",
        "    judge_response = response.choices[0].message.content.strip()\n",
        "\n",
        "    for line in judge_response.split(\"\\n\"):\n",
        "        if line.startswith(\"Label:\"):\n",
        "            label = line[len(\"Label:\") :].strip()\n",
        "        if line.startswith(\"Critique:\"):\n",
        "            critique = line[len(\"Critique:\") :].strip()\n",
        "\n",
        "    return label, critique\n",
        "\n",
        "\n",
        "for i, d in enumerate(d_dataset, start=1):\n",
        "    print(f\"{i}/{len(d_dataset)}\")\n",
        "\n",
        "    label, critique = get_judge_response(judge_prompt, d[\"prompt\"], d[\"response\"])\n",
        "\n",
        "    d[\"llm_label\"] = label\n",
        "    d[\"llm_critique\"] = critique"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4SCWSTAEYWJd",
        "outputId": "c8cab33f-d85c-46ee-f80d-8e2778aef466"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 27,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7,\n        \"min\": 1,\n        \"max\": 27,\n        \"num_unique_values\": 27,\n        \"samples\": [\n          9,\n          14,\n          10\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"query\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 27,\n        \"samples\": [\n          \"How does the boosting method work to minimize total error in a prediction model?\",\n          \"What is the purpose of using Tensor Processing Units (TPUs) in deep learning?\",\n          \"What is the structure and purpose of a database table in managing data?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prompt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 27,\n        \"samples\": [\n          \"Context information is below.\\n---------------------\\nSource 1:\\n-----\\nrepresents an error or gradient. This breakdown helps us manage and minimize the total error more effectively. The boosting method uses a model to predict each piece. We iteratively refine our final prediction by summing up all these predicted errors:   where m_i(x) are the models predicting each error piece.   In practice  when implementing the boosting method  we use the following Taylor expansion to approximate the loss function:   We can illustrate the boosting algorithm with the following example:   Just as a supermarket sells bread at varying discounts based on freshness to maximize sales  similarly  the boosting method handles the residuals of a loss function. Earlier residuals (lower-order terms) significantly reduce the loss value  while later residuals (higher-order terms) have a diminishing effect  akin to the decreasing value of less fresh bread. This process continues until no further reduction in loss can be achieved.   The boosting algorithm accumulates these contributions to minimize the total loss value  refining the models predictions iteratively. Each iteration builds on the previous one  incorporating the residuals to improve overall prediction accuracy.   An Intuitive Example of BoostingLets walk through a straightforward Boosting example using linear regression.   Imagine we predict y = 7 given x = 2. We now create a model that makes this prediction through iterative steps.   InitializationWe start with an initial prediction. For simplicity  lets assume our initial prediction is zero:   First IterationPerform Linear Regression: begin by fitting a simple linear regression model to our data point (x = 2  y = 7):Using x = 2 and y = 7  we solve for a and b:   Assume the model predicts p_1 = 4. The residual error e_1 is:   Update the Prediction: update the initial prediction with this new value:Second IterationFit Residuals: perform linear regression on the residual e_1:Using x = 2 and e_1 = 3  we solve for the new prediction p2:   Assume the model predicts p_2 = 2. The new residual e_2 is:   Update the Prediction: add this new value to our prediction:Third IterationFit Residuals: continue by fitting linear regression on the new residual e_2:Using x = 2 and e_2 =\\n-----\\n\\nSource 2:\\n-----\\nresidual error e_1 is:   Update the Prediction: update the initial prediction with this new value:Second IterationFit Residuals: perform linear regression on the residual e_1:Using x = 2 and e_1 = 3  we solve for the new prediction p2:   Assume the model predicts p_2 = 2. The new residual e_2 is:   Update the Prediction: add this new value to our prediction:Third IterationFit Residuals: continue by fitting linear regression on the new residual e_2:Using x = 2 and e_2 = 1  we solve for the new prediction p_3:   Assume the model predicts p_3=1. The new residual e_3 is:   Update the Prediction: add this final value to our prediction:This example illustrates the basic mechanism of boosting using linear regression. But in practice more complex models like decision trees are utilized to predict residuals  leading to techniques such as Gradient Boosting Trees.   Gradient Boosting TreesWhy Not Use Linear Regression in Boosting?In our previous example  we used linear regression to predict gradients in each boosting step to demonstrate the basic concept of boosting. However  linear regression is not suitable due to the orthogonality of error and prediction.   In linear regression  the error (residual) is orthogonal to the predictions  meaning the residuals are uncorrelated with the predicted values:   This approach doesnt capture complex error patterns. Because of this orthogonality  fitting a linear regression model to the residuals multiple times is the same as fitting it once to the original data. Therefore  using linear regression in an iterative boosting framework doesnt add extra value over a single linear regression model.   Why Use Tree Models in Boosting?Boosting is an ensemble algorithm  meaning the final prediction is obtained by combining the outputs from multiple models. Interaction and bagging efficiency are important to the production of highly accurate results. Tree models meet these requirements for several reasons:   Non-linearity and Accurate Gradient Prediction Tree models can capture non-linear relationships between features and the target variable  accurately predicting gradients.   Local Approximation Tree models split data into regions and fit simple models (like constants) within these regions. This local approximation can precisely capture the datas patterns.   Handling\\n-----\\n\\nSource 3:\\n-----\\nA Deep Dive into the Mechanisms of Boosting with Step-by-Step Examples  Leading to the Development of Boosting in Machine Learning   Boosting is a powerful machine learning technique widely used to improve the performance of predictive models. Its a key component in many winning models on platforms like Kaggle. But what makes boosting so effective? How does it work? This article will break down the boosting algorithm both mathematically and practically.   Well start with the basics  explaining the mathematical foundation of the boosting algorithm in simple terms. Youll see how boosting iteratively improves predictions by correcting errors from previous models. This process is crucial for mastering and effectively applying boosting.   Next  well move to hands-on implementation. Instead of pre-built Python packages  well write the boosting algorithm from scratch  using decision trees as base learners. This approach will help you understand how boosting works step by step.   Finally  well introduce XGBoost  a popular gradient-boosting implementation. Well explain how XGBoost fits into the general boosting framework and guide you through creating a raw XGBoost model.   By the end of this article  youll understand how boosting works and how to implement and customize it for your predictive modeling tasks.   How Does Boosting WorkImagine we have a model represented by the equation:   f(x) is our models prediction  and y is the actual value. Our goal is to make our model as accurate as possible by minimizing the total error  known as the loss function:   To minimize the loss function  we split it into many smaller pieces. The loss function can often be complex or have no explicit form  so we express it as a sum of smaller components:   Each piece represents an error or gradient. This breakdown helps us manage and minimize the total error more effectively. The boosting method uses a model to predict each piece. We iteratively refine our final prediction by summing up all these predicted errors:   where m_i(x) are the models predicting each error piece.   In practice  when implementing the boosting method  we use the following Taylor expansion to approximate the loss function:   We can illustrate the boosting algorithm with the following example:   Just as a supermarket sells bread at varying discounts based on freshness to maximize sales  similarly  the boosting method handles the residuals of a loss function.\\n-----\\n\\nSource 4:\\n-----\\n[2]  [3]]) y = np.array([0  0  3  -1]) # Initialize and fit the model model = GradientBoostingRegressor(n_estimators=100  learning_rate=0.5  max_depth=1  random_state=0) model.fit(X  y) # Predictions predictions = model.predict(X) print(Predictions:  predictions) # Plotting the results plt.figure(figsize=(10  6)) plt.scatter(X  y  color='red'  label='Actual data') plt.plot(X  predictions  color='blue'  label='Predicted data') plt.xlabel('X') plt.ylabel('y') plt.title('Boosting Gradient Tree Model') plt.legend() plt.show()Here is the output of the raw method:   Here is the output of the GradientBoostingRegressor method:   By comparing the raw boosting with the GradientBoostingRegressor from SKLEARN  we can better understand the inner workings of the boosting algorithm and how it iteratively improves the models performance.   General Framework and Mathematical FoundationsBased on the example in the previous section. we summarize the following general boosting procedure:   1. Initialization:   The initial model is typically a simple model  such as predicting the mean   of the target values.   2. Iterative Process:   For each iteration i  the following steps are performed:   Calculate errors:   The errors e_i represent the discrepancies between the actual target values y and the predictions from the previous model. The error function can be Mean Absolute Percentage Error (MAPE)  Mean Squared Error (MSE)  or others.   Fit Model to Errors:   Update the Model:   In addition  the predictions are updated by adding the new models predictions  scaled by a learning rate   to the previous models predictions.   We now investigate the logistics for the boosting steps above; this is related to minimizing a loss function L(y  f(x)) that measures the difference between the actual target values y and the models predictions f(x).   A loss function is used in machine learning to see how close a models predictions are to the real data. Think of it as a way to measure the error or badness of the model predictions. The lower the loss function value  the\\n-----\\n\\nSource 5:\\n-----\\nUpdate the Model:   In addition  the predictions are updated by adding the new models predictions  scaled by a learning rate   to the previous models predictions.   We now investigate the logistics for the boosting steps above; this is related to minimizing a loss function L(y  f(x)) that measures the difference between the actual target values y and the models predictions f(x).   A loss function is used in machine learning to see how close a models predictions are to the real data. Think of it as a way to measure the error or badness of the model predictions. The lower the loss function value  the better the model is performing. It helps to calculate the total error between the model and the sample data. The loss function can often be explicitly expressed as a math formula  such as linear and logistic regressions  but there might be no simple math form like a decision tree and neural networks.   The steps can be mathematically formalized as follows:   The initial model f_0(x) is chosen to minimize the loss function over the training data.   2. Gradient Descent on Errors: For each iteration i: Compute the Gradient and Hessian:   The gradient represents the direction of the steepest increase in the loss function. The Hessian provides information about the curvature of the loss function. Computing the gradient and Hessian is essential because we use them in building the decision tree model below.   Fit a Decision Tree:   In this step where we fit a Decision Tree  the tree model m_i(x) is trained to predict the gradient g_i with a regularization term that involves the Hessian h_i. Here  the objective function (i.e. the approximation of the loss function) combines the gradient and the Hessian to determine the optimal split and leaf in the decision tree. The formulation   ensures that the tree is trained to approximate the gradient and account for the curvature from the Hessian. Therefore  the tree model primarily predicts the gradient while being influenced by the Hessian to improve the robustness and stability of the model.   Regularization is used in the boosting method to prevent overfitting and ensure that the model generalizes well to new data. The regularization term (f) can include both L1 and L2 penalties:   where  and  are regularization parameters\\n-----\\n---------------------\\nGiven the context information and not prior knowledge, answer the query.\\nQuery: How does the boosting method work to minimize total error in a prediction model?\\nAnswer: \",\n          \"Context information is below.\\n---------------------\\nSource 1:\\n-----\\nthat could perform 8-bit multiply-and-adds on signed or unsigned integers. The 16-bit products were then collected in 4 MiB of 32-bit Accumulators below the matrix unit. Then there are other components like the activation pipeline that could perform activation functions on the resulting matrix.   For more details about the Google TPU that was released in 2017 read this very interesting paper where they discuss in detail the TPUs design and performance!   In-datacenter performance analysis of a tensor processing unit U+007C IEEE Conference Publication U+007C IEEE Xplore   TPU v2 and v3Improving upon the design of TPU v1 Google released the specifications of TPU v2 and v3 as well with some major changes:   Interconnect  A critical element of any chip design is the interconnect which decides how fast is the inter-chip communication. An on-device switch called Interconnect Router (see above figure) provides deadlock-free routing. It enables a 2D torus topology of interconnect.Memory  A major performance bottleneck in TPU v1 was the limited memory bandwidth of DRAM. This problem was somewhat solved using the HBM (High Bandwidth Memory) DRAM in TPU v2. It offers 20 times the bandwidth of TPU v1 by using an interposer substrate that connects the TPU v2 chip via thirty-two 128-bit buses to 4-stacks of DRAM chips.Multiple smaller MXU units per chip  While TPUv1 featured a MXU of the size 256x256  it was reduced to 128x128 in TPUv2 onwards and has multiple MXUs per chip. Larger MXUs require more memory bandwidth for optimal chip utilization. Google analyzed that convolutional model utilization ranged between 37%-48% for 128x128 MXUs  which was 1.6x of a single 256x256 MXU (22%-30%). The reason that Google has come up with this is that some convolutions are naturally smaller than 256x256  which leaves parts of the MXU unused.For more details regarding Google TPU v2 and v3:   A Domain Specific Supercomputer for Training Deep Neural Networks U+007C ACM   AI and Memory WallThe amount of computing needed to train modern deep learning models and perform inference using\\n-----\\n\\nSource 2:\\n-----\\n# Training on TPU with TensorFlow<Tip>If you don't need long explanations and just want TPU code samples to get started with, check out [our TPU example notebook!](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/tpu_training-tf.ipynb)</Tip>### What is a TPU?A TPU is a **Tensor Processing Unit.** They are hardware designed by Google, which are used to greatly speed up the tensor computations within neural networks, much like GPUs. They can be used for both network training and inference. They are generally accessed through Google\\u2019s cloud services, but small TPUs can also be accessed directly for free through Google Colab and Kaggle Kernels.Because [all TensorFlow models in \\ud83e\\udd17 Transformers are Keras models](https://huggingface.co/blog/tensorflow-philosophy), most of the methods in this document are generally applicable to TPU training for any Keras model! However, there are a few points that are specific to the HuggingFace ecosystem (hug-o-system?) of Transformers and Datasets, and we\\u2019ll make sure to flag them up when we get to them.### What kinds of TPU are available?New users are often very confused by the range of TPUs, and the different ways to access them. The first key distinction to understand is the difference between **TPU Nodes** and **TPU VMs.**When you use a **TPU Node**, you are effectively indirectly accessing a remote TPU. You will need a separate VM, which will initialize your network and data pipeline and then forward them to the remote node. When you use a TPU on Google Colab, you are accessing it in the **TPU Node** style.Using TPU Nodes can have some quite unexpected behaviour for people who aren\\u2019t used to them! In particular, because the TPU is located on a physically different system to the machine you\\u2019re running your Python code on, your data cannot be local to your machine - any data pipeline that loads from your machine\\u2019s internal storage will totally fail! Instead, data must be stored in Google Cloud Storage where your data pipeline can still access it, even when the pipeline is running on the remote TPU node.<Tip>If you can fit all your data in memory as `np.ndarray` or `tf.Tensor`, then you can `fit()`\\n-----\\n\\nSource 3:\\n-----\\nnumber of rows and columns of the IFMAP and FILTER respectively. T is the temporal dimension which in the case of the output stationary represents the convolution window size.   As described by the figure above  we can conclude that the number of cycles for the systolic array to perform a matrix multiplication is:   Obviously  in the real world  we do not have unlimited MACs. In that case  we divide the workload by the number of available MAC units and therefore get the following expression for timing:   Here  we assume that R and C are the actual dimensions of the systolic array and Sr and Sc are the required dimensions. To decrease this time  we can increase the number of MAC units  a process we can call scaling up. Another approach is to have multiple MAC array units that perform the compute in parallel  which can be called scaling out. This further reduces the time needed to complete the operation.   A look inside Google TPUOriginsBack in 2013  a projection at Google showed that if people searched using voice even for 3 minutes a day  it would result in doubling the computing demand of Googles datacenters. Speech recognition models that used DNN were very expensive to perform inference using traditional CPUs. Therefore  they started working on a custom ASIC (application-specific integrated circuit) that would perform inference efficiently. The goal was 10x performance over GPUs. The outcome of this effort was the Google Tensor Processing Unit. Google TPU was based on the systolic array architecture.   TPU v1As you are now aware systolic array-based AI accelerators are composed of MAC units. Googles original TPU implementation consisted of 256x256 MAC units (see Matrix Multiply Unit in the figure above) that could perform 8-bit multiply-and-adds on signed or unsigned integers. The 16-bit products were then collected in 4 MiB of 32-bit Accumulators below the matrix unit. Then there are other components like the activation pipeline that could perform activation functions on the resulting matrix.   For more details about the Google TPU that was released in 2017 read this very interesting paper where they discuss in detail the TPUs design and performance!   In-datacenter performance analysis of a tensor processing unit U+007C IEEE Conference Publication U+007C IEEE Xplore   TPU v2 and\\n-----\\n\\nSource 4:\\n-----\\nstyle.Using TPU Nodes can have some quite unexpected behaviour for people who aren\\u2019t used to them! In particular, because the TPU is located on a physically different system to the machine you\\u2019re running your Python code on, your data cannot be local to your machine - any data pipeline that loads from your machine\\u2019s internal storage will totally fail! Instead, data must be stored in Google Cloud Storage where your data pipeline can still access it, even when the pipeline is running on the remote TPU node.<Tip>If you can fit all your data in memory as `np.ndarray` or `tf.Tensor`, then you can `fit()` on that data even when using Colab or a TPU Node, without needing to upload it to Google Cloud Storage.</Tip><Tip>**\\ud83e\\udd17Specific Hugging Face Tip\\ud83e\\udd17:** The methods `Dataset.to_tf_dataset()` and its higher-level wrapper `model.prepare_tf_dataset()` , which you will see throughout our TF code examples, will both fail on a TPU Node. The reason for this is that even though they create a `tf.data.Dataset` it is not a \\u201cpure\\u201d `tf.data` pipeline and uses `tf.numpy_function` or `Dataset.from_generator()` to stream data from the underlying HuggingFace `Dataset`. This HuggingFace `Dataset` is backed by data that is on a local disc and which the remote TPU Node will not be able to read.</Tip>The second way to access a TPU is via a **TPU VM.** When using a TPU VM, you connect directly to the machine that the TPU is attached to, much like training on a GPU VM. TPU VMs are generally easier to work with, particularly when it comes to your data pipeline. All of the above warnings do not apply to TPU VMs!This is an opinionated document, so here\\u2019s our opinion: **Avoid using TPU Node if possible.** It is more confusing and more difficult to debug than TPU VMs. It is also likely to be unsupported in future - Google\\u2019s latest TPU, TPUv4, can only be accessed as a TPU VM, which suggests that TPU Nodes are increasingly going to become a \\u201clegacy\\u201d access method. However, we understand that the only free TPU access is on Colab and Kaggle Kernels, which uses TPU Node - so we\\u2019ll try to\\n-----\\n\\nSource 5:\\n-----\\nBajwa  R.   & Yoon  D. H. (2017  June). In-datacenter performance analysis of a tensor processing unit. In Proceedings of the 44th annual international symposium on computer architecture (pp. 112).Jouppi  N. P.  Yoon  D. H.  Kurian  G.  Li  S.  Patil  N.  Laudon  J.   & Patterson  D. (2020). A domain-specific supercomputer for training deep neural networks. Communications of the ACM  63(7)  6778.Gholami  A.  Yao  Z.  Kim  S.  Hooper  C.  Mahoney  M. W.  & Keutzer  K. (2024). AI and memory wall. IEEE Micro.Samajdar  A.  Joseph  J. M.  Zhu  Y.  Whatmough  P.  Mattina  M.  & Krishna  T. (2020  August). A systematic methodology for characterizing scalability of dnn accelerators using scale-sim. In 2020 IEEE International Symposium on Performance Analysis of Systems and Software (ISPASS) (pp. 5868). IEEE.\\n-----\\n---------------------\\nGiven the context information and not prior knowledge, answer the query.\\nQuery: What is the purpose of using Tensor Processing Units (TPUs) in deep learning?\\nAnswer: \",\n          \"Context information is below.\\n---------------------\\nSource 1:\\n-----\\n\\\"State\\\" NVARCHAR(40),     \\\"Country\\\" NVARCHAR(40),     \\\"PostalCode\\\" NVARCHAR(10),     \\\"Phone\\\" NVARCHAR(24),     \\\"Fax\\\" NVARCHAR(24),     \\\"Email\\\" NVARCHAR(60),     PRIMARY KEY (\\\"EmployeeId\\\"),     FOREIGN KEY(\\\"ReportsTo\\\") REFERENCES \\\"Employee\\\" (\\\"EmployeeId\\\")    )        /*    3 rows from Employee table:    EmployeeIdLastNameFirstNameTitleReportsToBirthDateHireDateAddressCityStateCountryPostalCodePhoneFaxEmail    1AdamsAndrewGeneral ManagerNone1962-02-18 00:00:002002-08-14 00:00:0011120 Jasper Ave NWEdmontonABCanadaT5K 2N1+1 (780) 428-9482+1 (780) 428-3457andrew@chinookcorp.com    2EdwardsNancySales Manager11958-12-08 00:00:002002-05-01 00:00:00825 8 Ave SWCalgaryABCanadaT2P 2T3+1 (403) 262-3443+1 (403) 262-3322nancy@chinookcorp.com    3PeacockJaneSales Support Agent21973-08-29 00:00:002002-04-01 00:00:001111 6 Ave SWCalgaryABCanadaT2P 5M5+1 (403) 262-3443+1 (403) 262-6712jane@chinookcorp.com    */            CREATE TABLE \\\"Genre\\\" (    \\\"GenreId\\\" INTEGER NOT NULL,     \\\"Name\\\" NVARCHAR(120),     PRIMARY KEY (\\\"GenreId\\\")    )        /*    3 rows from Genre table:    GenreIdName    1Rock    2Jazz    3Metal    */\\n-----\\n\\nSource 2:\\n-----\\nvideo file    */            CREATE TABLE \\\"Playlist\\\" (    \\\"PlaylistId\\\" INTEGER NOT NULL,     \\\"Name\\\" NVARCHAR(120),     PRIMARY KEY (\\\"PlaylistId\\\")    )        /*    3 rows from Playlist table:    PlaylistIdName    1Music    2Movies    3TV Shows    */            CREATE TABLE \\\"PlaylistTrack\\\" (    \\\"PlaylistId\\\" INTEGER NOT NULL,     \\\"TrackId\\\" INTEGER NOT NULL,     PRIMARY KEY (\\\"PlaylistId\\\", \\\"TrackId\\\"),     FOREIGN KEY(\\\"TrackId\\\") REFERENCES \\\"Track\\\" (\\\"TrackId\\\"),     FOREIGN KEY(\\\"PlaylistId\\\") REFERENCES \\\"Playlist\\\" (\\\"PlaylistId\\\")    )        /*    3 rows from PlaylistTrack table:    PlaylistIdTrackId    13402    13389    13390    */            CREATE TABLE \\\"Track\\\" (    \\\"TrackId\\\" INTEGER NOT NULL,     \\\"Name\\\" NVARCHAR(200) NOT NULL,     \\\"AlbumId\\\" INTEGER,     \\\"MediaTypeId\\\" INTEGER NOT NULL,     \\\"GenreId\\\" INTEGER,     \\\"Composer\\\" NVARCHAR(220),     \\\"Milliseconds\\\" INTEGER NOT NULL,     \\\"Bytes\\\" INTEGER,     \\\"UnitPrice\\\" NUMERIC(10, 2) NOT NULL,     PRIMARY KEY (\\\"TrackId\\\"),     FOREIGN KEY(\\\"MediaTypeId\\\") REFERENCES \\\"MediaType\\\" (\\\"MediaTypeId\\\"),     FOREIGN KEY(\\\"GenreId\\\") REFERENCES \\\"Genre\\\" (\\\"GenreId\\\"),     FOREIGN KEY(\\\"AlbumId\\\") REFERENCES \\\"Album\\\" (\\\"AlbumId\\\")    )        /*    3 rows from Track table:    TrackIdNameAlbumIdMediaTypeIdGenreIdComposerMillisecondsBytesUnitPrice    1For Those About To Rock (We\\n-----\\n\\nSource 3:\\n-----\\nthe user question. In this case, we might think to simplify our model's job by grouping the tables together. We'll just ask the model to choose between categories \\\"Music\\\" and \\\"Business\\\", and then take care of selecting all the relevant tables from there:```pythonsystem = \\\"\\\"\\\"Return the names of any SQL tables that are relevant to the user question.The tables are:MusicBusiness\\\"\\\"\\\"prompt = ChatPromptTemplate.from_messages(    [        (\\\"system\\\", system),        (\\\"human\\\", \\\"{input}\\\"),    ])category_chain = prompt | llm_with_tools | output_parsercategory_chain.invoke({\\\"input\\\": \\\"What are all the genres of Alanis Morisette songs\\\"})```    [Table(name='Music'), Table(name='Business')]```pythonfrom typing import Listdef get_tables(categories: List[Table]) -> List[str]:    tables = []    for category in categories:        if category.name == \\\"Music\\\":            tables.extend(                [                    \\\"Album\\\",                    \\\"Artist\\\",                    \\\"Genre\\\",                    \\\"MediaType\\\",                    \\\"Playlist\\\",                    \\\"PlaylistTrack\\\",                    \\\"Track\\\",                ]            )        elif category.name == \\\"Business\\\":            tables.extend([\\\"Customer\\\", \\\"Employee\\\", \\\"Invoice\\\", \\\"InvoiceLine\\\"])    return tablestable_chain = category_chain | get_tablestable_chain.invoke({\\\"input\\\": \\\"What are all the\\n-----\\n\\nSource 4:\\n-----\\nand feed this into an output parser to reconstruct the object from the model's response.```{=mdx}import ChatModelTabs from \\\"@theme/ChatModelTabs\\\";<ChatModelTabs customVarName=\\\"llm\\\" />``````python# | output: false# | echo: falsefrom langchain_openai import ChatOpenAIllm = ChatOpenAI()``````pythonfrom langchain_core.output_parsers.openai_tools import PydanticToolsParserfrom langchain_core.prompts import ChatPromptTemplatefrom langchain_core.pydantic_v1 import BaseModel, Fieldclass Table(BaseModel):    \\\"\\\"\\\"Table in SQL database.\\\"\\\"\\\"    name: str = Field(description=\\\"Name of table in SQL database.\\\")table_names = \\\"\\\\n\\\".join(db.get_usable_table_names())system = f\\\"\\\"\\\"Return the names of ALL the SQL tables that MIGHT be relevant to the user question. \\\\The tables are:{table_names}Remember to include ALL POTENTIALLY RELEVANT tables, even if you're not sure that they're needed.\\\"\\\"\\\"prompt = ChatPromptTemplate.from_messages(    [        (\\\"system\\\", system),        (\\\"human\\\", \\\"{input}\\\"),    ])llm_with_tools = llm.bind_tools([Table])output_parser = PydanticToolsParser(tools=[Table])table_chain = prompt | llm_with_tools | output_parsertable_chain.invoke({\\\"input\\\": \\\"What are all the genres of Alanis Morisette songs\\\"})```    [Table(name='Genre')]This works pretty well! Except, as we'll see below, we actually need a few other tables as well. This would be pretty difficult for the model to know based just on the user question. In this case, we might think to simplify our model's job by grouping the tables together. We'll just ask the model to choose between categories \\\"Music\\\" and \\\"Business\\\", and then take care of selecting all the relevant tables from there:```pythonsystem = \\\"\\\"\\\"Return the names of any SQL tables that are relevant to the user question.The tables are:MusicBusiness\\\"\\\"\\\"prompt = ChatPromptTemplate.from_messages(    [        (\\\"system\\\", system),        (\\\"human\\\", \\\"{input}\\\"),    ])category_chain = prompt |\\n-----\\n\\nSource 5:\\n-----\\n00:00:00Ulleva\\u030alsveien 14OsloNoneNorway01713.96    382021-01-03 00:00:00Gre\\u0301trystraat 63BrusselsNoneBelgium10005.94    */            CREATE TABLE \\\"InvoiceLine\\\" (    \\\"InvoiceLineId\\\" INTEGER NOT NULL,     \\\"InvoiceId\\\" INTEGER NOT NULL,     \\\"TrackId\\\" INTEGER NOT NULL,     \\\"UnitPrice\\\" NUMERIC(10, 2) NOT NULL,     \\\"Quantity\\\" INTEGER NOT NULL,     PRIMARY KEY (\\\"InvoiceLineId\\\"),     FOREIGN KEY(\\\"TrackId\\\") REFERENCES \\\"Track\\\" (\\\"TrackId\\\"),     FOREIGN KEY(\\\"InvoiceId\\\") REFERENCES \\\"Invoice\\\" (\\\"InvoiceId\\\")    )        /*    3 rows from InvoiceLine table:    InvoiceLineIdInvoiceIdTrackIdUnitPriceQuantity    1120.991    2140.991    3260.991    */            CREATE TABLE \\\"MediaType\\\" (    \\\"MediaTypeId\\\" INTEGER NOT NULL,     \\\"Name\\\" NVARCHAR(120),     PRIMARY KEY (\\\"MediaTypeId\\\")    )        /*    3 rows from MediaType table:    MediaTypeIdName    1MPEG audio file    2Protected AAC audio file    3Protected MPEG-4 video file    */            CREATE TABLE \\\"Playlist\\\" (    \\\"PlaylistId\\\" INTEGER NOT NULL,     \\\"Name\\\" NVARCHAR(120),     PRIMARY KEY (\\\"PlaylistId\\\")    )        /*    3 rows from Playlist table:    PlaylistIdName    1Music    2Movies    3TV Shows    */            CREATE TABLE \\\"PlaylistTrack\\\" (\\n-----\\n---------------------\\nGiven the context information and not prior knowledge, answer the query.\\nQuery: What is the structure and purpose of a database table in managing data?\\nAnswer: \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"response\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 27,\n        \"samples\": [\n          \"The boosting method works to minimize total error in a prediction model through an iterative process that focuses on correcting the errors made by previous models. Here\\u2019s how it operates:\\n\\n1. **Initialization**: The process begins with an initial model, which is typically a simple one that might predict the mean of the target values.\\n\\n2. **Iterative Refinement**: In each iteration, boosting calculates the prediction errors (residuals) from the current model. These residuals represent the discrepancies between the actual target values and the predictions made by the model.\\n\\n3. **Error Prediction**: A new model (often a decision tree) is then fitted specifically to these residuals. This model aims to predict the errors made by the previous predictions.\\n\\n4. **Gradient and Hessian**: The boosting algorithm uses the gradient of the loss function to determine the direction of improvement. The gradient indicates the direction of steepest ascent in the loss function, while the Hessian provides curvature information. These metrics help to train the new model effectively, ensuring it focuses on the most significant errors.\\n\\n5. **Model Update**: The predictions from the new model are scaled by a learning rate and added to the previous model\\u2019s predictions. This step updates the overall prediction by incorporating the newly learned information.\\n\\n6. **Repeat**: The process of calculating residuals, fitting a new model, and updating predictions continues for a specified number of iterations or until the loss converges to a satisfactory level.\\n\\nBy iteratively correcting the model\\u2019s predictions based on the errors of prior models and using mathematical foundations like the gradient and Hessian, boosting effectively minimizes the total error in the prediction model, leading to improved accuracy and performance.\",\n          \"The purpose of using Tensor Processing Units (TPUs) in deep learning is to accelerate tensor computations, which are fundamental to the training and inference of neural networks. TPUs are specialized hardware designed by Google to provide significantly improved performance over traditional CPUs and even GPUs for deep learning tasks. They enhance the efficiency of operations such as matrix multiplications, enabling faster processing of large models and datasets. TPUs leverage architectures like systolic arrays and advanced memory bandwidth features to optimize deep learning workloads, making them particularly suitable for applications involving deep neural networks, such as speech recognition and image classification. Overall, TPUs help meet the growing computational demands of modern AI applications by delivering higher throughput and efficiency.\",\n          \"The structure of a database table typically consists of rows and columns, where each column represents a specific attribute or field of the data, and each row corresponds to a unique record or entry in the table. \\n\\nKey components of a database table include:\\n\\n1. **Columns (Fields)**: Each column has a defined data type (e.g., INTEGER, NVARCHAR, DATETIME) and represents a specific attribute of the data being stored. For example, in an \\\"Employee\\\" table, columns might include \\\"EmployeeId,\\\" \\\"FirstName,\\\" \\\"LastName,\\\" \\\"Title,\\\" and \\\"Email.\\\"\\n\\n2. **Rows (Records)**: Each row in the table corresponds to a single record, containing data for each field defined by the columns. For instance, a row in the \\\"Employee\\\" table would contain data for one employee, including their ID, name, title, and contact information.\\n\\n3. **Primary Key**: This is a unique identifier for each record in the table, ensuring that no two rows can have the same value for this field. For example, \\\"EmployeeId\\\" might serve as the primary key in an \\\"Employee\\\" table.\\n\\n4. **Foreign Key**: This establishes relationships between tables, linking records in one table to records in another. For example, if an \\\"Invoice\\\" table includes a \\\"CustomerId\\\" foreign key, it references the unique identifier in the \\\"Customer\\\" table, thereby associating invoices with specific customers.\\n\\nThe purpose of a database table in managing data is to organize and store related data efficiently, making it easy to retrieve, manipulate, and analyze. This structured approach allows for effective querying, ensuring that users can obtain relevant information quickly and accurately based on the relationships and constraints defined within the database schema. \\n\\nFor example, in a relational database, tables like \\\"Employee,\\\" \\\"Genre,\\\" and \\\"Invoice\\\" work together, with foreign keys linking them, to maintain data integrity and provide meaningful insights across various datasets.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"domain_expert_label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Bad\",\n          \"Good\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"domain_expert_critique\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 27,\n        \"samples\": [\n          \"The explanation provides a basic overview of the iterative process used in boosting, including error calculation and model updates. However, the answer feels generic and somewhat repetitive, lacking a deeper dive into key elements like regularization techniques or the specific role of the Hessian in refining predictions. While it covers the main steps, it does not fully capture the complexity and nuance of boosting as described in the context.\",\n          \"The response accurately details that TPUs are specialized hardware designed to accelerate tensor computations, essential for training and inference in deep learning. It compares TPUs with other hardware like CPUs and GPUs and highlights their advantages, fully addressing the query.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"llm_label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Bad\",\n          \"Good\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"llm_critique\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 27,\n        \"samples\": [\n          \"The response accurately describes the boosting method's iterative process of minimizing prediction errors, aligning well with the provided sources. It covers key points, such as initialization, error prediction, and model updating, and includes specifics on using gradients and Hessians, making it clear and concise. The explanation is relevant, specific, and free from inaccuracies, effectively summarizing how boosting reduces total error in prediction models.\",\n          \"The response accurately describes the purpose of TPUs in deep learning, covering key points such as acceleration of tensor computations, improved performance over CPUs/GPUs, and suitability for deep neural networks. It aligns well with the provided sources and maintains clarity, relevance, and specificity. It also mentions the architectural aspects like systolic arrays and advanced memory features, providing a comprehensive overview without errors or misleading claims.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-d0cd999d-6f2f-464c-a380-bfe0699cb1f5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>query</th>\n",
              "      <th>prompt</th>\n",
              "      <th>response</th>\n",
              "      <th>domain_expert_label</th>\n",
              "      <th>domain_expert_critique</th>\n",
              "      <th>llm_label</th>\n",
              "      <th>llm_critique</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>What are some strategies to improve the perfor...</td>\n",
              "      <td>Context information is below.\\n---------------...</td>\n",
              "      <td>To improve the performance of a Retrieval-Augm...</td>\n",
              "      <td>Good</td>\n",
              "      <td>The response comprehensively lists multiple st...</td>\n",
              "      <td>Good</td>\n",
              "      <td>The response effectively covers strategies to ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>What is dequantization and how does it relate ...</td>\n",
              "      <td>Context information is below.\\n---------------...</td>\n",
              "      <td>Dequantization is the process of converting lo...</td>\n",
              "      <td>Good</td>\n",
              "      <td>The answer accurately defines dequantization a...</td>\n",
              "      <td>Good</td>\n",
              "      <td>The response accurately explains dequantizatio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>How can you utilize a GPU to speed up the trai...</td>\n",
              "      <td>Context information is below.\\n---------------...</td>\n",
              "      <td>To utilize a GPU to speed up the training proc...</td>\n",
              "      <td>Good</td>\n",
              "      <td>The response provides a detailed, multi-facete...</td>\n",
              "      <td>Good</td>\n",
              "      <td>The response aligns well with the sources, cov...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>What are the specific characters used in Markd...</td>\n",
              "      <td>Context information is below.\\n---------------...</td>\n",
              "      <td>The specific characters used in Markdown for s...</td>\n",
              "      <td>Bad</td>\n",
              "      <td>The response is overly generic and lacks speci...</td>\n",
              "      <td>Bad</td>\n",
              "      <td>The response does not match the source materia...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>How can you use the Transformers library to pe...</td>\n",
              "      <td>Context information is below.\\n---------------...</td>\n",
              "      <td>To use the Transformers library for inference ...</td>\n",
              "      <td>Good</td>\n",
              "      <td>The answer is well-detailed and practical, off...</td>\n",
              "      <td>Good</td>\n",
              "      <td>The response effectively matches the source ma...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>What techniques can be used to finetune large ...</td>\n",
              "      <td>Context information is below.\\n---------------...</td>\n",
              "      <td>To fine-tune large AI models on a single GPU, ...</td>\n",
              "      <td>Good</td>\n",
              "      <td>The response effectively outlines a range of t...</td>\n",
              "      <td>Good</td>\n",
              "      <td>The response successfully covers key technique...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>What are some strategies to handle variable-si...</td>\n",
              "      <td>Context information is below.\\n---------------...</td>\n",
              "      <td>To handle variable-sized inputs efficiently in...</td>\n",
              "      <td>Good</td>\n",
              "      <td>The answer lists several effective strategies ...</td>\n",
              "      <td>Good</td>\n",
              "      <td>The response accurately covers various strateg...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>What are the main challenges addressed by Retr...</td>\n",
              "      <td>Context information is below.\\n---------------...</td>\n",
              "      <td>Retrieval-Augmented Generation (RAG) addresses...</td>\n",
              "      <td>Bad</td>\n",
              "      <td>While the response identifies a few challenges...</td>\n",
              "      <td>Good</td>\n",
              "      <td>The response effectively covers key challenges...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>How does the boosting method work to minimize ...</td>\n",
              "      <td>Context information is below.\\n---------------...</td>\n",
              "      <td>The boosting method works to minimize total er...</td>\n",
              "      <td>Bad</td>\n",
              "      <td>The explanation provides a basic overview of t...</td>\n",
              "      <td>Good</td>\n",
              "      <td>The response accurately describes the boosting...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>What is the structure and purpose of a databas...</td>\n",
              "      <td>Context information is below.\\n---------------...</td>\n",
              "      <td>The structure of a database table typically co...</td>\n",
              "      <td>Bad</td>\n",
              "      <td>The response outlines the basic components of ...</td>\n",
              "      <td>Good</td>\n",
              "      <td>The response accurately explains the structure...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>11</td>\n",
              "      <td>How does CodexGraph facilitate the interaction...</td>\n",
              "      <td>Context information is below.\\n---------------...</td>\n",
              "      <td>CodexGraph facilitates the interaction between...</td>\n",
              "      <td>Good</td>\n",
              "      <td>The response clearly explains that CodexGraph ...</td>\n",
              "      <td>Good</td>\n",
              "      <td>The response accurately explains how CodexGrap...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>12</td>\n",
              "      <td>What are the capabilities of the Nougat model ...</td>\n",
              "      <td>Context information is below.\\n---------------...</td>\n",
              "      <td>The Nougat model supports both training and in...</td>\n",
              "      <td>Bad</td>\n",
              "      <td>The response is overly generic and lacks speci...</td>\n",
              "      <td>Bad</td>\n",
              "      <td>The response fails to specifically explain the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>13</td>\n",
              "      <td>How can you restructure JSON data to be loaded...</td>\n",
              "      <td>Context information is below.\\n---------------...</td>\n",
              "      <td>To restructure JSON data for correct loading i...</td>\n",
              "      <td>Good</td>\n",
              "      <td>The answer provides a clear, step-by-step appr...</td>\n",
              "      <td>Good</td>\n",
              "      <td>The response aligns well with the context prov...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>14</td>\n",
              "      <td>What is the purpose of using Tensor Processing...</td>\n",
              "      <td>Context information is below.\\n---------------...</td>\n",
              "      <td>The purpose of using Tensor Processing Units (...</td>\n",
              "      <td>Good</td>\n",
              "      <td>The response accurately details that TPUs are ...</td>\n",
              "      <td>Good</td>\n",
              "      <td>The response accurately describes the purpose ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>15</td>\n",
              "      <td>What is the purpose of using the forward metho...</td>\n",
              "      <td>Context information is below.\\n---------------...</td>\n",
              "      <td>The purpose of using the `forward` method in `...</td>\n",
              "      <td>Bad</td>\n",
              "      <td>The response is overly simplistic, stating onl...</td>\n",
              "      <td>Good</td>\n",
              "      <td>The response accurately describes the purpose ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>16</td>\n",
              "      <td>What is the role of temperature in the distill...</td>\n",
              "      <td>Context information is below.\\n---------------...</td>\n",
              "      <td>In the distillation process of neural networks...</td>\n",
              "      <td>Good</td>\n",
              "      <td>The answer thoroughly explains how temperature...</td>\n",
              "      <td>Good</td>\n",
              "      <td>The response accurately explains the role of t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>17</td>\n",
              "      <td>What steps can be taken to find a suitable adv...</td>\n",
              "      <td>Context information is below.\\n---------------...</td>\n",
              "      <td>To find a suitable advisor for research in a s...</td>\n",
              "      <td>Good</td>\n",
              "      <td>The response provides a comprehensive list of ...</td>\n",
              "      <td>Good</td>\n",
              "      <td>The response is comprehensive and aligns well ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>18</td>\n",
              "      <td>What distinguishes reinforcement learning from...</td>\n",
              "      <td>Context information is below.\\n---------------...</td>\n",
              "      <td>Reinforcement learning (RL) is distinguished f...</td>\n",
              "      <td>Good</td>\n",
              "      <td>The answer effectively distinguishes reinforce...</td>\n",
              "      <td>Bad</td>\n",
              "      <td>The response does not align with the provided ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>19</td>\n",
              "      <td>What are the main stages involved in the Graph...</td>\n",
              "      <td>Context information is below.\\n---------------...</td>\n",
              "      <td>The main stages involved in the GraphRAG workf...</td>\n",
              "      <td>Bad</td>\n",
              "      <td>Although the response correctly lists the thre...</td>\n",
              "      <td>Good</td>\n",
              "      <td>The response accurately identifies and describ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>20</td>\n",
              "      <td>How can you ensure that audio samples in a dat...</td>\n",
              "      <td>Context information is below.\\n---------------...</td>\n",
              "      <td>To ensure that audio samples in a dataset have...</td>\n",
              "      <td>Good</td>\n",
              "      <td>The response provides a clear and practical ex...</td>\n",
              "      <td>Good</td>\n",
              "      <td>The response accurately describes the process ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>21</td>\n",
              "      <td>What are some advantages of using OpenRouter f...</td>\n",
              "      <td>Context information is below.\\n---------------...</td>\n",
              "      <td>Some advantages of using OpenRouter for AI mod...</td>\n",
              "      <td>Good</td>\n",
              "      <td>The response provides a clear and comprehensiv...</td>\n",
              "      <td>Good</td>\n",
              "      <td>The response effectively summarizes the advant...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>22</td>\n",
              "      <td>What are the potential benefits of using AI to...</td>\n",
              "      <td>Context information is below.\\n---------------...</td>\n",
              "      <td>The potential benefits of using AI tools to sa...</td>\n",
              "      <td>Good</td>\n",
              "      <td>The answer effectively outlines multiple benef...</td>\n",
              "      <td>Good</td>\n",
              "      <td>The response provides a comprehensive list of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>23</td>\n",
              "      <td>What are the benefits of pruning in neural net...</td>\n",
              "      <td>Context information is below.\\n---------------...</td>\n",
              "      <td>Pruning in neural networks offers several bene...</td>\n",
              "      <td>Good</td>\n",
              "      <td>This response directly addresses the query by ...</td>\n",
              "      <td>Good</td>\n",
              "      <td>The response effectively summarizes the benefi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>24</td>\n",
              "      <td>What is the role of output parsers in processi...</td>\n",
              "      <td>Context information is below.\\n---------------...</td>\n",
              "      <td>The provided context does not explicitly menti...</td>\n",
              "      <td>Bad</td>\n",
              "      <td>The answer begins by noting that the provided ...</td>\n",
              "      <td>Good</td>\n",
              "      <td>The response accurately acknowledges the lack ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>25</td>\n",
              "      <td>What optimization technique is recommended for...</td>\n",
              "      <td>Context information is below.\\n---------------...</td>\n",
              "      <td>The provided excerpts do not include specific ...</td>\n",
              "      <td>Bad</td>\n",
              "      <td>The response simply states that the context do...</td>\n",
              "      <td>Good</td>\n",
              "      <td>The response correctly states the absence of i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>26</td>\n",
              "      <td>What are Text-Attributed Graphs (TAGs) and how...</td>\n",
              "      <td>Context information is below.\\n---------------...</td>\n",
              "      <td>Text-Attributed Graphs (TAGs) are a type of gr...</td>\n",
              "      <td>Good</td>\n",
              "      <td>The answer clearly explains that Text-Attribut...</td>\n",
              "      <td>Bad</td>\n",
              "      <td>The response does not align with the provided ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>27</td>\n",
              "      <td>How do image labeling services contribute to t...</td>\n",
              "      <td>Context information is below.\\n---------------...</td>\n",
              "      <td>Image labeling services play a crucial role in...</td>\n",
              "      <td>Good</td>\n",
              "      <td>The response thoroughly explains the role of i...</td>\n",
              "      <td>Bad</td>\n",
              "      <td>The response does not align with the provided ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d0cd999d-6f2f-464c-a380-bfe0699cb1f5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d0cd999d-6f2f-464c-a380-bfe0699cb1f5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d0cd999d-6f2f-464c-a380-bfe0699cb1f5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cccb3fcc-20e0-4342-8b44-863d4aad6605\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cccb3fcc-20e0-4342-8b44-863d4aad6605')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cccb3fcc-20e0-4342-8b44-863d4aad6605 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_5d3ffa38-53a2-4a4a-82db-e4f933371cd9\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_5d3ffa38-53a2-4a4a-82db-e4f933371cd9 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "    id                                              query  \\\n",
              "0    1  What are some strategies to improve the perfor...   \n",
              "1    2  What is dequantization and how does it relate ...   \n",
              "2    3  How can you utilize a GPU to speed up the trai...   \n",
              "3    4  What are the specific characters used in Markd...   \n",
              "4    5  How can you use the Transformers library to pe...   \n",
              "5    6  What techniques can be used to finetune large ...   \n",
              "6    7  What are some strategies to handle variable-si...   \n",
              "7    8  What are the main challenges addressed by Retr...   \n",
              "8    9  How does the boosting method work to minimize ...   \n",
              "9   10  What is the structure and purpose of a databas...   \n",
              "10  11  How does CodexGraph facilitate the interaction...   \n",
              "11  12  What are the capabilities of the Nougat model ...   \n",
              "12  13  How can you restructure JSON data to be loaded...   \n",
              "13  14  What is the purpose of using Tensor Processing...   \n",
              "14  15  What is the purpose of using the forward metho...   \n",
              "15  16  What is the role of temperature in the distill...   \n",
              "16  17  What steps can be taken to find a suitable adv...   \n",
              "17  18  What distinguishes reinforcement learning from...   \n",
              "18  19  What are the main stages involved in the Graph...   \n",
              "19  20  How can you ensure that audio samples in a dat...   \n",
              "20  21  What are some advantages of using OpenRouter f...   \n",
              "21  22  What are the potential benefits of using AI to...   \n",
              "22  23  What are the benefits of pruning in neural net...   \n",
              "23  24  What is the role of output parsers in processi...   \n",
              "24  25  What optimization technique is recommended for...   \n",
              "25  26  What are Text-Attributed Graphs (TAGs) and how...   \n",
              "26  27  How do image labeling services contribute to t...   \n",
              "\n",
              "                                               prompt  \\\n",
              "0   Context information is below.\\n---------------...   \n",
              "1   Context information is below.\\n---------------...   \n",
              "2   Context information is below.\\n---------------...   \n",
              "3   Context information is below.\\n---------------...   \n",
              "4   Context information is below.\\n---------------...   \n",
              "5   Context information is below.\\n---------------...   \n",
              "6   Context information is below.\\n---------------...   \n",
              "7   Context information is below.\\n---------------...   \n",
              "8   Context information is below.\\n---------------...   \n",
              "9   Context information is below.\\n---------------...   \n",
              "10  Context information is below.\\n---------------...   \n",
              "11  Context information is below.\\n---------------...   \n",
              "12  Context information is below.\\n---------------...   \n",
              "13  Context information is below.\\n---------------...   \n",
              "14  Context information is below.\\n---------------...   \n",
              "15  Context information is below.\\n---------------...   \n",
              "16  Context information is below.\\n---------------...   \n",
              "17  Context information is below.\\n---------------...   \n",
              "18  Context information is below.\\n---------------...   \n",
              "19  Context information is below.\\n---------------...   \n",
              "20  Context information is below.\\n---------------...   \n",
              "21  Context information is below.\\n---------------...   \n",
              "22  Context information is below.\\n---------------...   \n",
              "23  Context information is below.\\n---------------...   \n",
              "24  Context information is below.\\n---------------...   \n",
              "25  Context information is below.\\n---------------...   \n",
              "26  Context information is below.\\n---------------...   \n",
              "\n",
              "                                             response domain_expert_label  \\\n",
              "0   To improve the performance of a Retrieval-Augm...                Good   \n",
              "1   Dequantization is the process of converting lo...                Good   \n",
              "2   To utilize a GPU to speed up the training proc...                Good   \n",
              "3   The specific characters used in Markdown for s...                 Bad   \n",
              "4   To use the Transformers library for inference ...                Good   \n",
              "5   To fine-tune large AI models on a single GPU, ...                Good   \n",
              "6   To handle variable-sized inputs efficiently in...                Good   \n",
              "7   Retrieval-Augmented Generation (RAG) addresses...                 Bad   \n",
              "8   The boosting method works to minimize total er...                 Bad   \n",
              "9   The structure of a database table typically co...                 Bad   \n",
              "10  CodexGraph facilitates the interaction between...                Good   \n",
              "11  The Nougat model supports both training and in...                 Bad   \n",
              "12  To restructure JSON data for correct loading i...                Good   \n",
              "13  The purpose of using Tensor Processing Units (...                Good   \n",
              "14  The purpose of using the `forward` method in `...                 Bad   \n",
              "15  In the distillation process of neural networks...                Good   \n",
              "16  To find a suitable advisor for research in a s...                Good   \n",
              "17  Reinforcement learning (RL) is distinguished f...                Good   \n",
              "18  The main stages involved in the GraphRAG workf...                 Bad   \n",
              "19  To ensure that audio samples in a dataset have...                Good   \n",
              "20  Some advantages of using OpenRouter for AI mod...                Good   \n",
              "21  The potential benefits of using AI tools to sa...                Good   \n",
              "22  Pruning in neural networks offers several bene...                Good   \n",
              "23  The provided context does not explicitly menti...                 Bad   \n",
              "24  The provided excerpts do not include specific ...                 Bad   \n",
              "25  Text-Attributed Graphs (TAGs) are a type of gr...                Good   \n",
              "26  Image labeling services play a crucial role in...                Good   \n",
              "\n",
              "                               domain_expert_critique llm_label  \\\n",
              "0   The response comprehensively lists multiple st...      Good   \n",
              "1   The answer accurately defines dequantization a...      Good   \n",
              "2   The response provides a detailed, multi-facete...      Good   \n",
              "3   The response is overly generic and lacks speci...       Bad   \n",
              "4   The answer is well-detailed and practical, off...      Good   \n",
              "5   The response effectively outlines a range of t...      Good   \n",
              "6   The answer lists several effective strategies ...      Good   \n",
              "7   While the response identifies a few challenges...      Good   \n",
              "8   The explanation provides a basic overview of t...      Good   \n",
              "9   The response outlines the basic components of ...      Good   \n",
              "10  The response clearly explains that CodexGraph ...      Good   \n",
              "11  The response is overly generic and lacks speci...       Bad   \n",
              "12  The answer provides a clear, step-by-step appr...      Good   \n",
              "13  The response accurately details that TPUs are ...      Good   \n",
              "14  The response is overly simplistic, stating onl...      Good   \n",
              "15  The answer thoroughly explains how temperature...      Good   \n",
              "16  The response provides a comprehensive list of ...      Good   \n",
              "17  The answer effectively distinguishes reinforce...       Bad   \n",
              "18  Although the response correctly lists the thre...      Good   \n",
              "19  The response provides a clear and practical ex...      Good   \n",
              "20  The response provides a clear and comprehensiv...      Good   \n",
              "21  The answer effectively outlines multiple benef...      Good   \n",
              "22  This response directly addresses the query by ...      Good   \n",
              "23  The answer begins by noting that the provided ...      Good   \n",
              "24  The response simply states that the context do...      Good   \n",
              "25  The answer clearly explains that Text-Attribut...       Bad   \n",
              "26  The response thoroughly explains the role of i...       Bad   \n",
              "\n",
              "                                         llm_critique  \n",
              "0   The response effectively covers strategies to ...  \n",
              "1   The response accurately explains dequantizatio...  \n",
              "2   The response aligns well with the sources, cov...  \n",
              "3   The response does not match the source materia...  \n",
              "4   The response effectively matches the source ma...  \n",
              "5   The response successfully covers key technique...  \n",
              "6   The response accurately covers various strateg...  \n",
              "7   The response effectively covers key challenges...  \n",
              "8   The response accurately describes the boosting...  \n",
              "9   The response accurately explains the structure...  \n",
              "10  The response accurately explains how CodexGrap...  \n",
              "11  The response fails to specifically explain the...  \n",
              "12  The response aligns well with the context prov...  \n",
              "13  The response accurately describes the purpose ...  \n",
              "14  The response accurately describes the purpose ...  \n",
              "15  The response accurately explains the role of t...  \n",
              "16  The response is comprehensive and aligns well ...  \n",
              "17  The response does not align with the provided ...  \n",
              "18  The response accurately identifies and describ...  \n",
              "19  The response accurately describes the process ...  \n",
              "20  The response effectively summarizes the advant...  \n",
              "21  The response provides a comprehensive list of ...  \n",
              "22  The response effectively summarizes the benefi...  \n",
              "23  The response accurately acknowledges the lack ...  \n",
              "24  The response correctly states the absence of i...  \n",
              "25  The response does not align with the provided ...  \n",
              "26  The response does not align with the provided ...  "
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Convert to pandas DataFrame\n",
        "df = pd.DataFrame(d_dataset)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "JA0nwq2ZYWHK",
        "outputId": "bf8d8790-ac8e-4f07-c3a4-bdc0b3387ee3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>llm_label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Good</th>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bad</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "llm_label\n",
              "Good    22\n",
              "Bad      5\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# How many \"Good\" and \"Bad\" annotations there are in the data (from the LLM)\n",
        "label_counts = df[\"llm_label\"].value_counts()\n",
        "label_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tWFc4qkSap7-"
      },
      "outputs": [],
      "source": [
        "# Let's save the final evaluation dataset with all the labels\n",
        "with open(\"d_dataset.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(d_dataset, f, indent=4, ensure_ascii=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIfQr2ifYlOs"
      },
      "source": [
        "# Let's see if the domain expert and the LLM-as-a-judge agree!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nz19_0ltZCWi"
      },
      "source": [
        "We'll use a measure called \"Cohen's Kappa\", which is a way to measure correlation between to lists of values.\n",
        "\n",
        "Cohen suggested the Kappa result be interpreted as follows: values ≤ 0 as indicating no agreement and 0.01–0.20 as none to slight, 0.21–0.40 as fair, 0.41– 0.60 as moderate, 0.61–0.80 as substantial, and 0.81–1.00 as almost perfect agreement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmil7uKVxItf",
        "outputId": "cfc0b4fd-4171-4824-d9b0-20dd3bdd169d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.63\n",
            "Cohen's Kappa: 0.06\n",
            "Confusion Matrix:\n",
            "[[15  3]\n",
            " [ 7  2]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, cohen_kappa_score, confusion_matrix\n",
        "\n",
        "# Labels\n",
        "expert_labels = [d[\"domain_expert_label\"] for d in d_dataset]\n",
        "llm_labels = [d[\"llm_label\"] for d in d_dataset]\n",
        "\n",
        "# Accuracy\n",
        "accuracy = accuracy_score(expert_labels, llm_labels)\n",
        "\n",
        "# Cohen's Kappa\n",
        "kappa = cohen_kappa_score(expert_labels, llm_labels)\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(expert_labels, llm_labels, labels=[\"Good\", \"Bad\"])\n",
        "\n",
        "# Display Results\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Cohen's Kappa: {kappa:.2f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3FWW-MZZNRY"
      },
      "source": [
        "# There's low agreement! Let's try improving the judge prompt leveraging the critiques"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYO0F3eyZsDG"
      },
      "source": [
        "We could do this manually, as we did here. Otherwise, we could do this with tools like alignevals where prompt optimizations are done automatically by LLMs and then A/B tested using the evaluation dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0gUWGTL3xInS"
      },
      "outputs": [],
      "source": [
        "# Second version of the LLM-as-a-judge-prompt\n",
        "\n",
        "judge_prompt = \"\"\"\n",
        "Your task is to evaluate pairs of input prompts and output responses using the detailed criteria below, incorporating insights from domain experts so that your evaluations align closely with expert judgments:\n",
        "\n",
        "1. Matches the Source: The response must directly reflect and reference details from the provided sources. It should include specific facts, examples, or terminology from the sources. Generic or unrelated content should result in a \"Bad\" rating.\n",
        "\n",
        "2. Covers Key Points: The response must address all main aspects of the query. For example, if the query requires discussing technical details or listing several components, the response must cover each one clearly. Omissions or superficial coverage should be noted.\n",
        "\n",
        "3. Clear & Concise: The response should be easy to understand, well-structured, and free of unnecessary jargon. It should provide sufficient context so that even non-experts can follow, but without extraneous detail.\n",
        "\n",
        "4. Relevant & Specific: The response must be strictly on-topic, providing precise and detailed information pertinent to the query. It should avoid vague generalizations or overly broad statements.\n",
        "\n",
        "5. Accurate Information: All details must be correct and consistent with the source material. Misleading or erroneous claims, even if partially correct, should lead to a \"Bad\" rating.\n",
        "\n",
        "Evaluation Guidelines:\n",
        "\n",
        "If the response explicitly incorporates source details, covers every key point with specificity, and is both clear and accurate, label it \"Good\".\n",
        "If it is generic, omits critical details, lacks direct source reference, or contains inaccuracies, label it \"Bad\".\n",
        "Provide a single-line critique (up to 100 words) explaining your reasoning—mention specific issues such as lack of technical detail, missing key points, or poor alignment with source content when applicable.\n",
        "\n",
        "Here's the input prompt to evaluate:\n",
        "-----\n",
        "{prompt}\n",
        "-----\n",
        "\n",
        "Here's the output response to evaluate:\n",
        "-----\n",
        "{response}\n",
        "-----\n",
        "\n",
        "Use this format for your response (but don't rewrite the \"-\" characters):\n",
        "-----\n",
        "Label: <good-or-bad>\n",
        "\n",
        "Critique: <critique>\n",
        "-----\n",
        "\"\"\".strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_NQ0n9yxIkD",
        "outputId": "f24b9f61-612b-4cad-d49a-5544aa8394e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.63\n",
            "Cohen's Kappa: 0.25\n",
            "Confusion Matrix:\n",
            "[[11  7]\n",
            " [ 3  6]]\n"
          ]
        }
      ],
      "source": [
        "# We update the LLM labels and critiques using the new prompt (same code as before)\n",
        "for i, d in enumerate(d_dataset, start=1):\n",
        "    print(f\"{i}/{len(d_dataset)}\")\n",
        "\n",
        "    label, critique = get_judge_response(judge_prompt, d[\"prompt\"], d[\"response\"])\n",
        "\n",
        "    d[\"llm_label\"] = label\n",
        "    d[\"llm_critique\"] = critique\n",
        "\n",
        "# We compute the agreement scores (same code as before)\n",
        "expert_labels = [d[\"domain_expert_label\"] for d in d_dataset]\n",
        "llm_labels = [d[\"llm_label\"] for d in d_dataset]\n",
        "accuracy = accuracy_score(expert_labels, llm_labels)\n",
        "kappa = cohen_kappa_score(expert_labels, llm_labels)\n",
        "conf_matrix = confusion_matrix(expert_labels, llm_labels, labels=[\"Good\", \"Bad\"])\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Cohen's Kappa: {kappa:.2f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIlZSgVRcjrm"
      },
      "source": [
        "Great! Cohen's Kappa went from 0.06 to 0.25, signaling a better agreement between the domain expert and the judge LLM! It can be seen from the confusion matrix as well.\n",
        "\n",
        "We stop here. In practice, we would do other iterations to improve the agreement."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpulvEnG8-2K"
      },
      "source": [
        "# Here's instead a different approach to evaluating RAG responses specifically: using LLM-based metrics like Answer Relevancy and Answer Faithfulness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oE8DIvLlwOE",
        "outputId": "e26fa98b-ce3d-47cb-cbf6-3de9d4457729"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "top_2 faithfulness_score: 0.95\n",
            "top_2 relevancy_score: 0.7\n",
            "====================\n",
            "top_4 faithfulness_score: 0.95\n",
            "top_4 relevancy_score: 0.85\n",
            "====================\n",
            "top_6 faithfulness_score: 0.95\n",
            "top_6 relevancy_score: 0.85\n",
            "====================\n",
            "top_8 faithfulness_score: 1.0\n",
            "top_8 relevancy_score: 0.85\n",
            "====================\n",
            "top_10 faithfulness_score: 0.9\n",
            "top_10 relevancy_score: 0.85\n",
            "====================\n"
          ]
        }
      ],
      "source": [
        "# --- Evaluate Generation: Relevancy and Faithfulness ---\n",
        "from llama_index.llms.openai import OpenAI\n",
        "from llama_index.core.evaluation import (\n",
        "    RelevancyEvaluator,\n",
        "    FaithfulnessEvaluator,\n",
        "    BatchEvalRunner,\n",
        ")\n",
        "\n",
        "# We'll use GPT-4o as a judge for generation evaluation\n",
        "judge_llm = OpenAI(temperature=0, model=\"gpt-4o\")\n",
        "\n",
        "faithfulness_evaluator = FaithfulnessEvaluator(llm=judge_llm)\n",
        "relevancy_evaluator = RelevancyEvaluator(llm=judge_llm)\n",
        "\n",
        "queries = list(rag_eval_dataset.queries.values())\n",
        "batch_eval_queries = queries[\n",
        "    :20\n",
        "]  # Limit the queries for demo purposes (avoid huge costs)\n",
        "\n",
        "runner = BatchEvalRunner(\n",
        "    {\"faithfulness\": faithfulness_evaluator, \"relevancy\": relevancy_evaluator},\n",
        "    workers=8,\n",
        ")\n",
        "\n",
        "for k in [2, 4, 6, 8, 10]:\n",
        "    index = VectorStoreIndex.from_vector_store(vector_store=vector_store)\n",
        "    query_engine = index.as_query_engine(similarity_top_k=k, llm=judge_llm)\n",
        "    eval_results = await runner.aevaluate_queries(\n",
        "        query_engine, queries=batch_eval_queries\n",
        "    )\n",
        "\n",
        "    faithfulness_score = sum(r.passing for r in eval_results[\"faithfulness\"]) / len(\n",
        "        eval_results[\"faithfulness\"]\n",
        "    )\n",
        "    relevancy_score = sum(r.passing for r in eval_results[\"relevancy\"]) / len(\n",
        "        eval_results[\"relevancy\"]\n",
        "    )\n",
        "\n",
        "    print(f\"top_{k} faithfulness_score: {faithfulness_score}\")\n",
        "    print(f\"top_{k} relevancy_score: {relevancy_score}\")\n",
        "    print(\"=\" * 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UGvvKqDK04L3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "l4lfl2DB2WPD"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00991f89b5164e3eb5675c6ed5282d58": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab8b7cfac0e941df9f3b3f0d79f9472a",
            "placeholder": "​",
            "style": "IPY_MODEL_e3f0e691660f451cbdcba99d72a45e30",
            "value": "vectorstore.zip: 100%"
          }
        },
        "01af4de4ded143408cc21277c48d3fba": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "028f9e9332fb421b8b8fc1289920856d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ebc7d3a0ca54526a0b38633951827a4",
            "placeholder": "​",
            "style": "IPY_MODEL_6a6c45a2f81b42cfbd5c385c4fb6dc21",
            "value": " 97.2M/97.2M [00:01&lt;00:00, 93.3MB/s]"
          }
        },
        "031b3786d01a4572add8fd266904a02e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "What are the capabilities of the Nougat model in terms of document processing?",
            "description_tooltip": null,
            "disabled": false,
            "indent": false,
            "layout": "IPY_MODEL_3092aa0eb3f1492fbb07112cea468bc4",
            "style": "IPY_MODEL_1439a53a48f04e9ea8254dfe88719590",
            "value": true
          }
        },
        "0457d91c5b914948b8104ca3fdde7a04": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "How can you use the Transformers library to perform inference with FastSpeech2Conformer and HiFi-GAN?",
            "description_tooltip": null,
            "disabled": false,
            "indent": false,
            "layout": "IPY_MODEL_1fb1a2034cd44e46a0b897bda068c2b5",
            "style": "IPY_MODEL_bb2367bd986e4c01ae25d97e24f1d267",
            "value": true
          }
        },
        "04e2e201c83a41f59780fa898608f586": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "initial"
          }
        },
        "0894f9b02b054c1b8294863e4c0e9d22": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "What are some advantages of using OpenRouter for AI model deployment?",
            "description_tooltip": null,
            "disabled": false,
            "indent": false,
            "layout": "IPY_MODEL_cb2063163f344327b47855fe840f3e4c",
            "style": "IPY_MODEL_922bdc1668354697b2b470473afd1ca8",
            "value": true
          }
        },
        "0c9465f6204e4ce4a3fc426c6755bd4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "How does the system handle multiple search queries to retrieve information efficiently?",
            "description_tooltip": null,
            "disabled": false,
            "indent": false,
            "layout": "IPY_MODEL_6bd018a2cad54e20af701860d41da47b",
            "style": "IPY_MODEL_9e8cf7d2d1ea4e2c98555310e9c96d53",
            "value": false
          }
        },
        "0d69049ecbae4d1097a36d74bfb50475": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "How can you restructure JSON data to be loaded into a Pandas DataFrame correctly?",
            "description_tooltip": null,
            "disabled": false,
            "indent": false,
            "layout": "IPY_MODEL_76a02c5eecec4c5fa2596be5b31b8c6a",
            "style": "IPY_MODEL_749a7ebbe8004bbf867924501e88054c",
            "value": true
          }
        },
        "12ebdefaf16147489eb1659359b4fc5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "How were health and safety measures managed for participants at the 2022 Winter Olympics?",
            "description_tooltip": null,
            "disabled": false,
            "indent": false,
            "layout": "IPY_MODEL_e35f7793b5d147d3a93740bda87472bf",
            "style": "IPY_MODEL_4d9d69d58aaf48759052cf4bd92c3cdd",
            "value": false
          }
        },
        "1439a53a48f04e9ea8254dfe88719590": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "initial"
          }
        },
        "1944196a72244f5b9a88b26af5341723": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "1fb1a2034cd44e46a0b897bda068c2b5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "202c31bc92a941a9a52d6fd02926c1be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "How does the boosting method work to minimize total error in a prediction model?",
            "description_tooltip": null,
            "disabled": false,
            "indent": false,
            "layout": "IPY_MODEL_a968983ee37045e098dae1aed98616eb",
            "style": "IPY_MODEL_7a41e193c34d4713990ac03f84f49388",
            "value": true
          }
        },
        "21f23d1671a5451fa5df72b68a2c775e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "What is the purpose of using Tensor Processing Units (TPUs) in deep learning?",
            "description_tooltip": null,
            "disabled": false,
            "indent": false,
            "layout": "IPY_MODEL_5e3766eaa0c34c42ac48d64756b87779",
            "style": "IPY_MODEL_b961b20951244ead9ea4d4ef020b0249",
            "value": true
          }
        },
        "24a76caa2e064b26be50a5c4a2d5150a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "26de460e5c8a451ea73579840865890d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ecb1abf3a7b4ccfbc211ac254046a34": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "What are some strategies to handle variable-sized inputs efficiently in batch processing for AI models?",
            "description_tooltip": null,
            "disabled": false,
            "indent": false,
            "layout": "IPY_MODEL_1944196a72244f5b9a88b26af5341723",
            "style": "IPY_MODEL_57cefad1900a4cd5be182cc3ef9c2b14",
            "value": true
          }
        },
        "2edbfea2ae114012bfb894bdb6e823ef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "3092aa0eb3f1492fbb07112cea468bc4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "31e9231f195440868a85b0767fa6c693": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "33bcbd92355e4990955147551fa2f344": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "What are the potential benefits of using AI tools to save time in business operations?",
            "description_tooltip": null,
            "disabled": false,
            "indent": false,
            "layout": "IPY_MODEL_41e003ce91534d93a2412b025e6efe6c",
            "style": "IPY_MODEL_4e47b4a8b0ac41f5b4c02790579eff3c",
            "value": true
          }
        },
        "38495dface7249bbb132bbbb986316b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "success",
            "description": "Save Cleaned Dataset",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_60eb932b5d0f40a889a9c0a736b66966",
            "style": "IPY_MODEL_958b423db36741d091bb3a5c99a26d93",
            "tooltip": ""
          }
        },
        "38694b49940a4273a393e7b9fbfeea1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "initial"
          }
        },
        "395d0abdd8bc4224bd45fc83a4d4023e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "39f8a4782c4944ef8d1ed3b3856730ca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "41e003ce91534d93a2412b025e6efe6c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "44bb89824ed645e28eb43a2cd2eb1e1f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "4665b831c005427dbadd8f90dc183233": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "How can you utilize a GPU to speed up the training process in PyTorch?",
            "description_tooltip": null,
            "disabled": false,
            "indent": false,
            "layout": "IPY_MODEL_01af4de4ded143408cc21277c48d3fba",
            "style": "IPY_MODEL_04e2e201c83a41f59780fa898608f586",
            "value": true
          }
        },
        "4a835f9aae4c410e90254cb2eb11d732": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "4c80aa96b8a24969b1efa5aaa130aec9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "initial"
          }
        },
        "4d9d69d58aaf48759052cf4bd92c3cdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "initial"
          }
        },
        "4e47b4a8b0ac41f5b4c02790579eff3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "initial"
          }
        },
        "5078ffc458d7476d99583d000d5522fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "What are the benefits of pruning in neural networks, especially for deployment on devices with limited resources?",
            "description_tooltip": null,
            "disabled": false,
            "indent": false,
            "layout": "IPY_MODEL_b255b421f6a74e53bf6a781d3c978024",
            "style": "IPY_MODEL_9b2ebad1f9f74a63b4fa6c4a7e1ffbe7",
            "value": true
          }
        },
        "525cc951c52942a09786a42958fabfb6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "52f0058d9a4e408cb108bb349a16e07a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "initial"
          }
        },
        "573a78fe4fee4b36ad5a9e9a7e6c6191": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "What optimization technique is recommended for fine-tuning Pix2Struct models?",
            "description_tooltip": null,
            "disabled": false,
            "indent": false,
            "layout": "IPY_MODEL_9f13a589664c40228dfd91fb1724744a",
            "style": "IPY_MODEL_8bdead914c3f481c976f2aa769742747",
            "value": true
          }
        },
        "57cefad1900a4cd5be182cc3ef9c2b14": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "initial"
          }
        },
        "57e6a71579724edb9bd311a6fda394f0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "584412541c72435997a177cb04a79cb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "What are the main challenges addressed by Retrieval-Augmented Generation in AI?",
            "description_tooltip": null,
            "disabled": false,
            "indent": false,
            "layout": "IPY_MODEL_6df1744835b0460b854eda9588005cb5",
            "style": "IPY_MODEL_9154b46948dd44ceafc88c103f5ea03a",
            "value": true
          }
        },
        "598672c85fc3450b8e4108d2b4e65c7c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "5acea6494e3b41f89ad05920b67a2119": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "initial"
          }
        },
        "5d37cee48c524be9a5589f0ebaa7e307": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "initial"
          }
        },
        "5e3766eaa0c34c42ac48d64756b87779": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "5fe674b691844723852b7acb115d3b15": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "60eb932b5d0f40a889a9c0a736b66966": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64a3d1b8b20b436cae5b4bfa73a76928": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "6666877048954f5cbb264d409cedd180": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "How do image labeling services contribute to the development and optimization of AI models?",
            "description_tooltip": null,
            "disabled": false,
            "indent": false,
            "layout": "IPY_MODEL_44bb89824ed645e28eb43a2cd2eb1e1f",
            "style": "IPY_MODEL_8c861eb631b045d3ae1f419e5a9fcd7a",
            "value": true
          }
        },
        "694f559a5fa540609a3f6ade929ad839": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": "1px solid gray",
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "400px",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": "scroll",
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "auto"
          }
        },
        "6a6c45a2f81b42cfbd5c385c4fb6dc21": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6bd018a2cad54e20af701860d41da47b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "6df1744835b0460b854eda9588005cb5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "6ebc7d3a0ca54526a0b38633951827a4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74658f35f4a74e65abab0fcdb10afc5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "initial"
          }
        },
        "749a7ebbe8004bbf867924501e88054c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "initial"
          }
        },
        "76a02c5eecec4c5fa2596be5b31b8c6a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "7a41e193c34d4713990ac03f84f49388": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "initial"
          }
        },
        "7dbd4bdeabcf43788c5067004d02404d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "What is the structure and purpose of a database table in managing data?",
            "description_tooltip": null,
            "disabled": false,
            "indent": false,
            "layout": "IPY_MODEL_395d0abdd8bc4224bd45fc83a4d4023e",
            "style": "IPY_MODEL_5acea6494e3b41f89ad05920b67a2119",
            "value": true
          }
        },
        "7e7292f27b0342e48b1615179372ffde": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "initial"
          }
        },
        "8007617e21dc461bbb8051eefc72a04f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26de460e5c8a451ea73579840865890d",
            "max": 97198458,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b5b05748c292474b9ff01ae8eb140f7c",
            "value": 97198458
          }
        },
        "80764679b76243f684ff1a4a85bb1f17": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "87696977eb014b23ac137e5f52840f1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "initial"
          }
        },
        "8ac95b6cf5c44c47afc9e36ca682604b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "How can you ensure that audio samples in a dataset have uniform length for processing in an AI model?",
            "description_tooltip": null,
            "disabled": false,
            "indent": false,
            "layout": "IPY_MODEL_80764679b76243f684ff1a4a85bb1f17",
            "style": "IPY_MODEL_c71f9f4460bd438ab3c5eb6f029e3fdb",
            "value": true
          }
        },
        "8bdead914c3f481c976f2aa769742747": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "initial"
          }
        },
        "8bfecb3c0f2c492f8751db0a13e145ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "initial"
          }
        },
        "8c861eb631b045d3ae1f419e5a9fcd7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "initial"
          }
        },
        "912e3eebd5394d19abb5d9d8cb5fbc64": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "9154b46948dd44ceafc88c103f5ea03a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "initial"
          }
        },
        "922bdc1668354697b2b470473afd1ca8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "initial"
          }
        },
        "92c527b12b57485fa6cc6d745e1abefe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "What is the purpose of using the forward method in ResNetModel for image classification?",
            "description_tooltip": null,
            "disabled": false,
            "indent": false,
            "layout": "IPY_MODEL_31e9231f195440868a85b0767fa6c693",
            "style": "IPY_MODEL_a47b856fe74e4014bffe69738e42feb9",
            "value": true
          }
        },
        "958b423db36741d091bb3a5c99a26d93": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "95d25b8aa4ed4aaeb960c66186b14143": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "What is the impact of changing generation options on the execution time when using XLA in text generation models?",
            "description_tooltip": null,
            "disabled": false,
            "indent": false,
            "layout": "IPY_MODEL_ae38a53b616c4bc3a2115615dffc935e",
            "style": "IPY_MODEL_97a69a1020e441cca91515d446ccf070",
            "value": false
          }
        },
        "9635faa543c545f4a1087630e35266e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "initial"
          }
        },
        "96832da295d24ac6864b7da2e4ed3087": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "What is the role of temperature in the distillation process of neural networks?",
            "description_tooltip": null,
            "disabled": false,
            "indent": false,
            "layout": "IPY_MODEL_4a835f9aae4c410e90254cb2eb11d732",
            "style": "IPY_MODEL_5d37cee48c524be9a5589f0ebaa7e307",
            "value": true
          }
        },
        "97a69a1020e441cca91515d446ccf070": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "initial"
          }
        },
        "9b2ebad1f9f74a63b4fa6c4a7e1ffbe7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "initial"
          }
        },
        "9d9ad3daab8845baab4e358a60b4d3bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "What is dequantization and how does it relate to quantization in AI models?",
            "description_tooltip": null,
            "disabled": false,
            "indent": false,
            "layout": "IPY_MODEL_bf2c9d27e7de4320a4872b9433a3acc7",
            "style": "IPY_MODEL_a5330fc4934e4b11ad2fde2e66639509",
            "value": true
          }
        },
        "9e69309e4ad946fca33f7cba74d6ddf4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "9e8cf7d2d1ea4e2c98555310e9c96d53": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "initial"
          }
        },
        "9f13a589664c40228dfd91fb1724744a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "a36450dc92cd49ac8e0aa0907de60c45": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "What is an example of how a chat API call can be structured using the OpenAI Python library?",
            "description_tooltip": null,
            "disabled": false,
            "indent": false,
            "layout": "IPY_MODEL_df6396dd4d244a42b210f367698408b5",
            "style": "IPY_MODEL_eecaa41ff1074b13ac3281c33d2fac6c",
            "value": false
          }
        },
        "a47b856fe74e4014bffe69738e42feb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "initial"
          }
        },
        "a5330fc4934e4b11ad2fde2e66639509": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "initial"
          }
        },
        "a968983ee37045e098dae1aed98616eb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "ab8b7cfac0e941df9f3b3f0d79f9472a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac770f29e10e461abb60c68f84daf21c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "What techniques can be used to finetune large AI models on a single GPU?",
            "description_tooltip": null,
            "disabled": false,
            "indent": false,
            "layout": "IPY_MODEL_5fe674b691844723852b7acb115d3b15",
            "style": "IPY_MODEL_38694b49940a4273a393e7b9fbfeea1d",
            "value": true
          }
        },
        "ae38a53b616c4bc3a2115615dffc935e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "b0c0532b701b437086ea7ca3f9a8fe77": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "b255b421f6a74e53bf6a781d3c978024": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "b5b05748c292474b9ff01ae8eb140f7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b8a7413f80a04088ad89f044201a56ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "How does CodexGraph facilitate the interaction between large language models and code repositories?",
            "description_tooltip": null,
            "disabled": false,
            "indent": false,
            "layout": "IPY_MODEL_b0c0532b701b437086ea7ca3f9a8fe77",
            "style": "IPY_MODEL_d75cae49da7c44bf93e208514f9f9c7e",
            "value": true
          }
        },
        "b961b20951244ead9ea4d4ef020b0249": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "initial"
          }
        },
        "bb2367bd986e4c01ae25d97e24f1d267": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "initial"
          }
        },
        "bf2c9d27e7de4320a4872b9433a3acc7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "c2f2e9a5941443f6bb1f26329f659ea4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "What types of checks are performed when opening a pull request on the Transformers library?",
            "description_tooltip": null,
            "disabled": false,
            "indent": false,
            "layout": "IPY_MODEL_525cc951c52942a09786a42958fabfb6",
            "style": "IPY_MODEL_7e7292f27b0342e48b1615179372ffde",
            "value": false
          }
        },
        "c71f9f4460bd438ab3c5eb6f029e3fdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "initial"
          }
        },
        "cb1b144fa4d64601a2c5639322587eb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "What are the specific characters used in Markdown for splitting text?",
            "description_tooltip": null,
            "disabled": false,
            "indent": false,
            "layout": "IPY_MODEL_57e6a71579724edb9bd311a6fda394f0",
            "style": "IPY_MODEL_4c80aa96b8a24969b1efa5aaa130aec9",
            "value": true
          }
        },
        "cb2063163f344327b47855fe840f3e4c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "cb6d92ff49d44b828ecd0d5fa9bbe84e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "What are some key considerations when evaluating changes in an LLM application?",
            "description_tooltip": null,
            "disabled": false,
            "indent": false,
            "layout": "IPY_MODEL_9e69309e4ad946fca33f7cba74d6ddf4",
            "style": "IPY_MODEL_52f0058d9a4e408cb108bb349a16e07a",
            "value": false
          }
        },
        "ce789ed25b914081a269f95da23ae708": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "What are some strategies to improve the performance of a RAG pipeline?",
            "description_tooltip": null,
            "disabled": false,
            "indent": false,
            "layout": "IPY_MODEL_64a3d1b8b20b436cae5b4bfa73a76928",
            "style": "IPY_MODEL_da34a0498d8b42d787eb9d9115213f54",
            "value": true
          }
        },
        "d0832c42f8dc4df98d42d5ebd8ef50a8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "d2c5b448888d4cae811bf51421f62151": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "initial"
          }
        },
        "d4d15e642fa1429b94cc378b735abb57": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "What are the main stages involved in the GraphRAG workflow?",
            "description_tooltip": null,
            "disabled": false,
            "indent": false,
            "layout": "IPY_MODEL_d0832c42f8dc4df98d42d5ebd8ef50a8",
            "style": "IPY_MODEL_9635faa543c545f4a1087630e35266e1",
            "value": true
          }
        },
        "d5cad02fa1574ec094a7fc7d20d720d9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d716718ff04e4e2ca10944add879998a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "What is the role of output parsers in processing the output of AI models?",
            "description_tooltip": null,
            "disabled": false,
            "indent": false,
            "layout": "IPY_MODEL_912e3eebd5394d19abb5d9d8cb5fbc64",
            "style": "IPY_MODEL_74658f35f4a74e65abab0fcdb10afc5a",
            "value": true
          }
        },
        "d75cae49da7c44bf93e208514f9f9c7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "initial"
          }
        },
        "da34a0498d8b42d787eb9d9115213f54": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "initial"
          }
        },
        "df6396dd4d244a42b210f367698408b5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "e35f7793b5d147d3a93740bda87472bf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "e3f0e691660f451cbdcba99d72a45e30": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eecaa41ff1074b13ac3281c33d2fac6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "initial"
          }
        },
        "ef1195a2b2ed40bda5254efb4598b3e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ce789ed25b914081a269f95da23ae708",
              "IPY_MODEL_9d9ad3daab8845baab4e358a60b4d3bf",
              "IPY_MODEL_4665b831c005427dbadd8f90dc183233",
              "IPY_MODEL_cb1b144fa4d64601a2c5639322587eb5",
              "IPY_MODEL_0457d91c5b914948b8104ca3fdde7a04",
              "IPY_MODEL_a36450dc92cd49ac8e0aa0907de60c45",
              "IPY_MODEL_ac770f29e10e461abb60c68f84daf21c",
              "IPY_MODEL_2ecb1abf3a7b4ccfbc211ac254046a34",
              "IPY_MODEL_584412541c72435997a177cb04a79cb9",
              "IPY_MODEL_0c9465f6204e4ce4a3fc426c6755bd4a",
              "IPY_MODEL_f91e19d4ba1d4cfaa7b146332ca777e2",
              "IPY_MODEL_202c31bc92a941a9a52d6fd02926c1be",
              "IPY_MODEL_7dbd4bdeabcf43788c5067004d02404d",
              "IPY_MODEL_b8a7413f80a04088ad89f044201a56ef",
              "IPY_MODEL_031b3786d01a4572add8fd266904a02e",
              "IPY_MODEL_0d69049ecbae4d1097a36d74bfb50475",
              "IPY_MODEL_21f23d1671a5451fa5df72b68a2c775e",
              "IPY_MODEL_c2f2e9a5941443f6bb1f26329f659ea4",
              "IPY_MODEL_92c527b12b57485fa6cc6d745e1abefe",
              "IPY_MODEL_96832da295d24ac6864b7da2e4ed3087",
              "IPY_MODEL_f7cd3613666940bea33f4f8ac3998dbb",
              "IPY_MODEL_fa0c3658c7e64b7f8749959f0e33c799",
              "IPY_MODEL_d4d15e642fa1429b94cc378b735abb57",
              "IPY_MODEL_8ac95b6cf5c44c47afc9e36ca682604b",
              "IPY_MODEL_0894f9b02b054c1b8294863e4c0e9d22",
              "IPY_MODEL_12ebdefaf16147489eb1659359b4fc5e",
              "IPY_MODEL_cb6d92ff49d44b828ecd0d5fa9bbe84e",
              "IPY_MODEL_33bcbd92355e4990955147551fa2f344",
              "IPY_MODEL_95d25b8aa4ed4aaeb960c66186b14143",
              "IPY_MODEL_5078ffc458d7476d99583d000d5522fa",
              "IPY_MODEL_d716718ff04e4e2ca10944add879998a",
              "IPY_MODEL_573a78fe4fee4b36ad5a9e9a7e6c6191",
              "IPY_MODEL_f34717b08ae94c4c92f6f91a16af0373",
              "IPY_MODEL_6666877048954f5cbb264d409cedd180"
            ],
            "layout": "IPY_MODEL_694f559a5fa540609a3f6ade929ad839"
          }
        },
        "f1b2f2d8b18947e7b8671b3311982630": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "initial"
          }
        },
        "f34717b08ae94c4c92f6f91a16af0373": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "What are Text-Attributed Graphs (TAGs) and how are they structured in terms of nodes and edges?",
            "description_tooltip": null,
            "disabled": false,
            "indent": false,
            "layout": "IPY_MODEL_598672c85fc3450b8e4108d2b4e65c7c",
            "style": "IPY_MODEL_8bfecb3c0f2c492f8751db0a13e145ba",
            "value": true
          }
        },
        "f430d1b2477f4c3eb5e3d7a398c423a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_00991f89b5164e3eb5675c6ed5282d58",
              "IPY_MODEL_8007617e21dc461bbb8051eefc72a04f",
              "IPY_MODEL_028f9e9332fb421b8b8fc1289920856d"
            ],
            "layout": "IPY_MODEL_d5cad02fa1574ec094a7fc7d20d720d9"
          }
        },
        "f7cd3613666940bea33f4f8ac3998dbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "What steps can be taken to find a suitable advisor for research in a specialized field like multimodal learning?",
            "description_tooltip": null,
            "disabled": false,
            "indent": false,
            "layout": "IPY_MODEL_2edbfea2ae114012bfb894bdb6e823ef",
            "style": "IPY_MODEL_d2c5b448888d4cae811bf51421f62151",
            "value": true
          }
        },
        "f91e19d4ba1d4cfaa7b146332ca777e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "How are labels and their corresponding IDs mapped when preparing to train a model for token classification?",
            "description_tooltip": null,
            "disabled": false,
            "indent": false,
            "layout": "IPY_MODEL_24a76caa2e064b26be50a5c4a2d5150a",
            "style": "IPY_MODEL_f1b2f2d8b18947e7b8671b3311982630",
            "value": false
          }
        },
        "fa0c3658c7e64b7f8749959f0e33c799": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "What distinguishes reinforcement learning from supervised and unsupervised learning?",
            "description_tooltip": null,
            "disabled": false,
            "indent": false,
            "layout": "IPY_MODEL_39f8a4782c4944ef8d1ed3b3856730ca",
            "style": "IPY_MODEL_87696977eb014b23ac137e5f52840f1f",
            "value": true
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
