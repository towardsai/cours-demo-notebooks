{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9bpz99INAc1"
      },
      "source": [
        "# Install Packages and Setup Variables\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "BeuFJKlj9jKz",
        "outputId": "3eb63c4a-7476-4b12-c296-680698bf29cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/150.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.7/150.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m679.1/679.1 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.0/241.0 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q google-generativeai==0.5.4 llama-index-llms-gemini==0.3.7 llama-index==0.11.23 openai==1.59.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CWholrWlt2OQ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "# Set the following API Keys in the Python environment. Will be used later.\n",
        "# We use OpenAI for the embedding model and Gemini-1.5-flash as our LLM.\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"<YOUR_OPENAI_KEY>\"\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"<YOUR_API_KEY>\"\n",
        "\n",
        "# from google.colab import userdata\n",
        "# os.environ[\"OPENAI_API_KEY\"] = userdata.get('openai_api_key')\n",
        "# os.environ[\"GOOGLE_API_KEY\"] = userdata.get('Google_api_key')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5eV5EnvNCMM"
      },
      "source": [
        "# Load Dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-7mRQ-mNJlm"
      },
      "source": [
        "## Download\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PsdOdMUNmEi"
      },
      "source": [
        "The dataset includes a subset of the documentation from the Llama-index library.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ImRCP7pACaI",
        "outputId": "2d7c6ff0-bff5-460c-a81b-10865b90adca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   115  100   115    0     0    350      0 --:--:-- --:--:-- --:--:--   351\n",
            "100  570k  100  570k    0     0  1258k      0 --:--:-- --:--:-- --:--:-- 1258k\n"
          ]
        }
      ],
      "source": [
        "!curl -L -o ./llama_index_150k.jsonl https://huggingface.co/datasets/towardsai-buster/llama-index-docs/raw/main/llama_index_data_150k.jsonl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZZLK_wyEc-L"
      },
      "source": [
        "## Read File and create LlamaIndex Documents\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "miUqycqAEfr7",
        "outputId": "006b17bf-3f98-40eb-bb7d-801b7828b880"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of documents: 56\n"
          ]
        }
      ],
      "source": [
        "from llama_index.core import Document\n",
        "import json\n",
        "\n",
        "\n",
        "def create_docs(input_file: str) -> list[Document]:\n",
        "    documents = []\n",
        "    with open(input_file, \"r\") as f:\n",
        "        for idx, line in enumerate(f, start=1):\n",
        "\n",
        "          data = json.loads(line)\n",
        "\n",
        "          required_keys = {\"doc_id\", \"content\", \"url\", \"name\", \"tokens\", \"source\"}\n",
        "          if not required_keys.issubset(data):\n",
        "              print(f\"Missing keys in line {idx}: {required_keys - set(data)}\")\n",
        "              continue\n",
        "\n",
        "          documents.append(\n",
        "              Document(\n",
        "                  doc_id=data[\"doc_id\"],\n",
        "                  text=data[\"content\"],\n",
        "                  metadata={  # type: ignore\n",
        "                      \"url\": data[\"url\"],\n",
        "                      \"title\": data[\"name\"],\n",
        "                      \"tokens\": data[\"tokens\"],\n",
        "                      \"source\": data[\"source\"],\n",
        "                  },\n",
        "                  excluded_llm_metadata_keys=[\n",
        "                      \"title\",\n",
        "                      \"tokens\",\n",
        "                      \"source\",\n",
        "                  ],\n",
        "                  excluded_embed_metadata_keys=[\n",
        "                      \"url\",\n",
        "                      \"tokens\",\n",
        "                      \"source\",\n",
        "                  ],\n",
        "              )\n",
        "          )\n",
        "\n",
        "    return documents\n",
        "\n",
        "\n",
        "# Convert the texts to Document objects.\n",
        "documents = create_docs(\"llama_index_150k.jsonl\")\n",
        "print(f\"Number of documents: {len(documents)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f86yksB9K571"
      },
      "source": [
        "# Generate Embedding\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "ecf37a6c224549339d7b8b83ed9827a4",
            "c521aeed12554508bb8c5748db9dcd92",
            "fdcc788ab37a412c8ee3dcb4b12b0a3f",
            "ed9ecf43df70492086c9238f2eaa2dd8",
            "04bd9cfa4cc2499ca38f8c1ea1e20997",
            "58ef6c9d1822459c97ddab17e6d41771",
            "4045a892c2964026811fa75572cbcedc",
            "e23f608b905c4fd7b13fd004ec7b47ea",
            "a69bd51ebe654f788b94e61ba639d564",
            "f8ba9dc5ac82431eb25409907808e312",
            "a0c0307b99544bd6b50f46f178e8c263",
            "8fd2dd781f8d40cebf36d72eb7b0f204",
            "8a2a484a97ca43e6ae4871370621de82",
            "f6feb863974d4611b346eacb9b448476",
            "23eda2b311a746849c5da8d2b4373005",
            "d60a7ed3ecd343be921a9e13a64f4ab5",
            "b88ad1feaab54566a9b791a35e21c8f3",
            "09218cec1f194529b2aedd258149353f",
            "c0553ae7897345329afbd46cfb585793",
            "9e4a53421a204ec381aebd687cb8cfb3",
            "07210b06a25941c2b44a97728a131f8e",
            "e71747c944024e1abe22a1cba24e07cd"
          ]
        },
        "id": "Bsa7Q-DoNWBk",
        "outputId": "44939749-07b6-4c20-fea6-36720279d56d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Parsing nodes:   0%|          | 0/56 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ecf37a6c224549339d7b8b83ed9827a4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating embeddings:   0%|          | 0/447 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8fd2dd781f8d40cebf36d72eb7b0f204"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from llama_index.core import VectorStoreIndex\n",
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "\n",
        "\n",
        "# Build index / generate embeddings using OpenAI embedding model\n",
        "index = VectorStoreIndex.from_documents(\n",
        "    documents,\n",
        "    embed_model=OpenAIEmbedding(model=\"text-embedding-3-small\"),\n",
        "    transformations=[SentenceSplitter(chunk_size=512, chunk_overlap=128)],\n",
        "    show_progress=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DoUxd8KK--Q"
      },
      "source": [
        "# Query Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "bUaNH97dEfh9"
      },
      "outputs": [],
      "source": [
        "# Define a query engine that is responsible for retrieving related pieces of text,\n",
        "# and using a LLM to formulate the final answer.\n",
        "\n",
        "from llama_index.llms.gemini import Gemini\n",
        "\n",
        "llm = Gemini(model=\"models/gemini-1.5-flash\", temperature=1, max_tokens=1000)\n",
        "\n",
        "query_engine = index.as_query_engine(llm=llm, similarity_top_k=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "id": "KHK4V_GRR6ZG",
        "outputId": "38c4f9fd-ef7b-4f40-86b6-b9644c1e8dee"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "There are several ways to set up a query engine, depending on your needs and data.  If you know which tables to query beforehand and the combined size of the schema and prompt fits within your context window, use a query engine directly.  If the table schema is too large for the context window, create a table schema index using  `SQLTableNodeMapping` and `ObjectIndex`, incorporating a `VectorStoreIndex`.  For natural language SQL queries, use `NLSQLTableQueryEngine`, specifying the relevant tables.  For more general querying, use the `index.as_query_engine()` method.  More complex scenarios might involve constructing a `RetrieverQueryEngine` with custom retrievers, postprocessors (like `SimilarityPostprocessor`), and response synthesizers.  Alternatively, a `SubQuestionQueryEngine` can be used for multi-document queries,  creating a `QueryEngineTool` for each index and using them to generate sub-queries.  Finally, for routing queries to different data sources, use a `RouterQueryEngine` with appropriate `QueryEngineTool`s for each sub-index.\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time taken:  3.9134440422058105\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "\n",
        "response = query_engine.query(\"How to setup a query engine in code?\")\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "display(Markdown(response.response))\n",
        "print(\"time taken: \", end - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "id": "S-BmyTBbNd9y",
        "outputId": "2f09af62-e0bd-4fd6-f107-e6b853015d9a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "To create an agent, begin by importing necessary components from LlamaIndex and loading environment variables from a `.env` file.  Then, define basic tools such as functions for multiplication and addition, creating `FunctionTool` objects from them.  Next, initialize the large language model (LLM), for example, using `OpenAI(model=\"gpt-3.5-turbo\", temperature=0)`.  Finally, create the agent using `ReActAgent.from_tools([multiply_tool, add_tool], llm=llm, verbose=True)`, providing the tools and LLM.  For local models, install Ollama and use `Ollama(model=\"mixtral:8x7b\", request_timeout=120.0)` instead of OpenAI.\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time taken:  2.789015293121338\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "\n",
        "response = query_engine.query(\"How to setup an agent in code?\")\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "display(Markdown(response.response))\n",
        "print(\"time taken: \", end - start)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_55vnPoSlID"
      },
      "source": [
        "# Setup Long Context Caching\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBSZTxjfSlID"
      },
      "source": [
        "For this section, we will be using the Gemini API\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_ehbBc8dGLQ"
      },
      "source": [
        "Note: You might encounter dependency issues, which may require restarting the session(delete the run time and reinstall). Please reinstall google-generativeai to the latest version. To use long-context caching in google-generativeai, ensure you have version 0.7.2 or higher."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-xVY9mXk-eN",
        "outputId": "a8ab0e35-2db9-418d-9fc8-a2ae6783a843"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.0/241.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q google-generativeai==0.8.3 llama-index==0.12.12 llama-index-llms-gemini==0.4.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "cPm3PFcy3SKp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"<YOUR_API_KEY>\"\n",
        "\n",
        "# from google.colab import userdata\n",
        "# os.environ[\"GOOGLE_API_KEY\"] = userdata.get('Google_api_key')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHlXwVnJ3V8V",
        "outputId": "3d223a0f-da57-4c3a-8f57-782842cae3f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   115  100   115    0     0    425      0 --:--:-- --:--:-- --:--:--   425\n",
            "100  570k  100  570k    0     0  1324k      0 --:--:-- --:--:-- --:--:-- 1324k\n"
          ]
        }
      ],
      "source": [
        "!curl -L -o ./llama_index_150k.jsonl https://huggingface.co/datasets/towardsai-buster/llama-index-docs/raw/main/llama_index_data_150k.jsonl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGuvt0-N3WsP",
        "outputId": "c2aae3f5-738d-4290-f68e-a365e137114a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of documents: 56\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import json\n",
        "from llama_index.core import Document\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "\n",
        "def create_docs(input_file: str) -> list[Document]:\n",
        "    documents = []\n",
        "    with open(input_file, \"r\") as f:\n",
        "        for idx, line in enumerate(f, start=1):\n",
        "\n",
        "          data = json.loads(line)\n",
        "\n",
        "          required_keys = {\"doc_id\", \"content\", \"url\", \"name\", \"tokens\", \"source\"}\n",
        "          if not required_keys.issubset(data):\n",
        "              print(f\"Missing keys in line {idx}: {required_keys - set(data)}\")\n",
        "              continue\n",
        "\n",
        "          documents.append(\n",
        "              Document(\n",
        "                  doc_id=data[\"doc_id\"],\n",
        "                  text=data[\"content\"],\n",
        "                  metadata={  # type: ignore\n",
        "                      \"url\": data[\"url\"],\n",
        "                      \"title\": data[\"name\"],\n",
        "                      \"tokens\": data[\"tokens\"],\n",
        "                      \"source\": data[\"source\"],\n",
        "                  },\n",
        "                  excluded_llm_metadata_keys=[\n",
        "                      \"title\",\n",
        "                      \"tokens\",\n",
        "                      \"source\",\n",
        "                  ],\n",
        "                  excluded_embed_metadata_keys=[\n",
        "                      \"url\",\n",
        "                      \"tokens\",\n",
        "                      \"source\",\n",
        "                  ],\n",
        "              )\n",
        "          )\n",
        "\n",
        "    return documents\n",
        "\n",
        "\n",
        "# Convert the texts to Document objects.\n",
        "documents = create_docs(\"llama_index_150k.jsonl\")\n",
        "print(f\"Number of documents: {len(documents)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "eGIFfZrBSlID"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import google.generativeai as genai\n",
        "from google.generativeai import caching\n",
        "from google.generativeai import GenerationConfig\n",
        "\n",
        "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ex4X8BE3SlIE"
      },
      "source": [
        "Convert the jsonl file to a text file for the Gemini API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcL6M1VpSlIE",
        "outputId": "58791336-4c66-470c-ec02-e5c939d1a6d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contents saved to llama_index_contents.txt\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "\n",
        "def create_text_file(input_file: str, output_file: str) -> None:\n",
        "    with open(input_file, \"r\") as f, open(output_file, \"w\") as out:\n",
        "        for line in f:\n",
        "            data = json.loads(line)\n",
        "            out.write(data[\"content\"] + \"\\n\\n\")  # Add two newlines between documents\n",
        "\n",
        "    print(f\"Contents saved to {output_file}\")\n",
        "\n",
        "\n",
        "create_text_file(\"llama_index_150k.jsonl\", \"llama_index_contents.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "l2S4vl3ySlIE"
      },
      "outputs": [],
      "source": [
        "document = genai.upload_file(path=\"llama_index_contents.txt\")\n",
        "model_name = \"gemini-1.5-flash-001\"\n",
        "\n",
        "cache = genai.caching.CachedContent.create(\n",
        "    model=model_name,\n",
        "    system_instruction=\"You answer questions about the LlamaIndex framework.\",\n",
        "    contents=[document],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "GsPYVW6hSlIF"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "model = genai.GenerativeModel.from_cached_content(cache)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86jV_ZiIFBKa"
      },
      "source": [
        "## Response Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 760
        },
        "id": "DtSYddEjEnLa",
        "outputId": "09a10728-658c-450f-8074-1df2904f29e8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "LlamaParse is a document parsing engine that is part of LlamaCloud. It offers state-of-the-art document parsing capabilities, specifically designed to extract structured data from various document formats like PDFs, HTML, and others.  \n\nHere's a breakdown of LlamaParse and its setup:\n\n**What LlamaParse Does**\n\n* **Document Extraction:** It can extract text, tables, and other relevant information from documents, even if they have complex formatting or layouts. This is important for making the information inside of documents accessible for LLMs.\n* **Structured Output:** It can output the extracted information in a standardized and structured format, such as JSON, Markdown, or CSV. This makes it easier to integrate the parsed data with your LLM applications. \n* **Handling Complex Documents:** It can handle various document types, including PDFs with complex layouts, nested tables, and other challenging structures.\n* **Advanced Parsing Options:** It provides additional features like keyword extraction, topic extraction, and sentiment analysis for enriching the parsed data.\n\n**Setting Up LlamaParse**\n\n1. **Sign up for LlamaCloud:** You need a LlamaCloud account to access LlamaParse. Sign up for free at [https://cloud.llamaindex.ai/](https://cloud.llamaindex.ai/).  \n2. **Obtain Your API Key:** After signing up, you will receive a LlamaCloud API key. You'll need this key to access the LlamaParse API.\n3. **Install the Library:**  Use pip to install the LlamaParse library in your Python environment:\n\n   ```bash\n   pip install llama-parse\n   ```\n4. **Set Environment Variable:** Configure your environment to use the LlamaCloud API key: \n\n   ```bash\n   export LLAMA_CLOUD_API_KEY=\"your_llamacloud_api_key\"\n   ```\n5. **Start Using LlamaParse:** \n\n   ```python\n   from llama_parse import LlamaParse\n\n   # Parse a PDF into Markdown\n   documents = LlamaParse(result_type=\"markdown\").load_data(\"./path/to/your/document.pdf\")\n\n   # Parse a PDF into JSON\n   documents = LlamaParse(result_type=\"json\").load_data(\"./path/to/your/document.pdf\")\n\n   # You can also provide additional options for parsing\n   documents = LlamaParse(result_type=\"markdown\", language=\"french\").load_data(\"./path/to/your/document.pdf\")\n   ```\n\n**Important Considerations**\n\n* **Free Tier:** LlamaCloud has a free tier that includes a certain amount of parsing credits per day. For larger-scale parsing, you can upgrade to a paid plan. \n* **Self-Hosted Option:** If you require higher levels of privacy or custom deployment, LlamaParse can also be self-hosted. \n* **LlamaHub Integration:** You can easily integrate LlamaParse with LlamaHub to access a wide variety of data connectors and extend the functionality of your LLM applications. \n\nLet me know if you have any other questions! \n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time taken:  6.802876234054565\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "response = model.generate_content(\n",
        "    \"What is LlamaParse, How to setup?\",\n",
        "    generation_config=GenerationConfig(max_output_tokens=1000),\n",
        ")\n",
        "end = time.time()\n",
        "display(Markdown(response.text))\n",
        "print(\"time taken: \", end - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2Rq1syJEsze",
        "outputId": "fc686a12-0f17-4674-d35b-dc8642868a00"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "prompt_token_count: 212097\n",
              "cached_content_token_count: 212087\n",
              "candidates_token_count: 640\n",
              "total_token_count: 212737"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "response.usage_metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4i_Pf7Y5EVi5"
      },
      "source": [
        "## First token response time in Straming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "id": "UyTXWVaREXYC",
        "outputId": "8c50f152-9d56-45a0-be18-f9058dec72b9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Let"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time taken:  2.8402929306030273\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "response = model.generate_content(\n",
        "    \"How to setup a Router query engine?\",\n",
        "    generation_config=GenerationConfig(max_output_tokens=1),\n",
        ")\n",
        "end = time.time()\n",
        "display(Markdown(response.text))\n",
        "print(\"time taken: \", end - start)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U3PKSPhof079"
      },
      "execution_count": 11,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ecf37a6c224549339d7b8b83ed9827a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c521aeed12554508bb8c5748db9dcd92",
              "IPY_MODEL_fdcc788ab37a412c8ee3dcb4b12b0a3f",
              "IPY_MODEL_ed9ecf43df70492086c9238f2eaa2dd8"
            ],
            "layout": "IPY_MODEL_04bd9cfa4cc2499ca38f8c1ea1e20997"
          }
        },
        "c521aeed12554508bb8c5748db9dcd92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58ef6c9d1822459c97ddab17e6d41771",
            "placeholder": "​",
            "style": "IPY_MODEL_4045a892c2964026811fa75572cbcedc",
            "value": "Parsing nodes: 100%"
          }
        },
        "fdcc788ab37a412c8ee3dcb4b12b0a3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e23f608b905c4fd7b13fd004ec7b47ea",
            "max": 56,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a69bd51ebe654f788b94e61ba639d564",
            "value": 56
          }
        },
        "ed9ecf43df70492086c9238f2eaa2dd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8ba9dc5ac82431eb25409907808e312",
            "placeholder": "​",
            "style": "IPY_MODEL_a0c0307b99544bd6b50f46f178e8c263",
            "value": " 56/56 [00:01&lt;00:00, 20.33it/s]"
          }
        },
        "04bd9cfa4cc2499ca38f8c1ea1e20997": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58ef6c9d1822459c97ddab17e6d41771": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4045a892c2964026811fa75572cbcedc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e23f608b905c4fd7b13fd004ec7b47ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a69bd51ebe654f788b94e61ba639d564": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f8ba9dc5ac82431eb25409907808e312": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0c0307b99544bd6b50f46f178e8c263": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8fd2dd781f8d40cebf36d72eb7b0f204": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8a2a484a97ca43e6ae4871370621de82",
              "IPY_MODEL_f6feb863974d4611b346eacb9b448476",
              "IPY_MODEL_23eda2b311a746849c5da8d2b4373005"
            ],
            "layout": "IPY_MODEL_d60a7ed3ecd343be921a9e13a64f4ab5"
          }
        },
        "8a2a484a97ca43e6ae4871370621de82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b88ad1feaab54566a9b791a35e21c8f3",
            "placeholder": "​",
            "style": "IPY_MODEL_09218cec1f194529b2aedd258149353f",
            "value": "Generating embeddings: 100%"
          }
        },
        "f6feb863974d4611b346eacb9b448476": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0553ae7897345329afbd46cfb585793",
            "max": 447,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9e4a53421a204ec381aebd687cb8cfb3",
            "value": 447
          }
        },
        "23eda2b311a746849c5da8d2b4373005": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07210b06a25941c2b44a97728a131f8e",
            "placeholder": "​",
            "style": "IPY_MODEL_e71747c944024e1abe22a1cba24e07cd",
            "value": " 447/447 [00:05&lt;00:00, 73.84it/s]"
          }
        },
        "d60a7ed3ecd343be921a9e13a64f4ab5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b88ad1feaab54566a9b791a35e21c8f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09218cec1f194529b2aedd258149353f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c0553ae7897345329afbd46cfb585793": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e4a53421a204ec381aebd687cb8cfb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "07210b06a25941c2b44a97728a131f8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e71747c944024e1abe22a1cba24e07cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}