{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/towardsai/cours-demo-notebooks/blob/main/exercice_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ZelpvKD-5JCb",
        "outputId": "abfeebe2-6075-4ad0-a4ee-2ccffccb9962"
      },
      "outputs": [],
      "source": [
        "# Installation des bibliothèques nécessaires (seulement pour Colab)\n",
        "!pip install instructor pydantic google-generativeai python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "K-AHd_gx5PIH"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/omar/Documents/ai_repos/cours-demo-notebooks/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "# Importation des bibliothèques\n",
        "import instructor\n",
        "import google.generativeai as genai\n",
        "from pydantic import BaseModel, Field\n",
        "from enum import Enum\n",
        "from typing import Literal\n",
        "from dotenv import load_dotenv\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PIXO3TMz5UY0"
      },
      "outputs": [],
      "source": [
        "# Configuration de l'API Gemini\n",
        "\n",
        "load_dotenv(\".env\")\n",
        "\n",
        "GOOGLE_API_KEY = \"\"  # Remplacez par votre clé API\n",
        "genai.configure(api_key=os.environ[\"GOOGLE_AI_STUDIO\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "uJ7u-ryvKeIL"
      },
      "outputs": [],
      "source": [
        "# 1. Définition des modèles Pydantic\n",
        "class Personne(BaseModel):\n",
        "    nom: str = Field(max_length=50)\n",
        "    age: int | str\n",
        "    role: str = Field(\n",
        "        description=\"Role de la personne dans la compagnie, ex: Développeur\",\n",
        "    )\n",
        "    compagnie: Literal[\"NeuroTech Systems\", \"VirtuaSoft\", \"Quantum Solutions\", \"OTHER\"]\n",
        "\n",
        "\n",
        "class ExtractionPersonnes(BaseModel):\n",
        "    reasoning: str = Field(\n",
        "        description=\"À partir des informations fournies, écris 'comment' tu vas t'y prendre pour extraire les informations du texte.\",\n",
        "    )\n",
        "    list_personnes: list[Personne] = Field(min_length=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "VQoWb0TOKeC7"
      },
      "outputs": [],
      "source": [
        "# 2. Initialisation du client Gemini avec JSON STRICT pour l'extraction SEULEMENT\n",
        "client = instructor.from_gemini(\n",
        "    client=genai.GenerativeModel(model_name=\"models/gemini-2.0-flash\"),\n",
        "    mode=instructor.Mode.GEMINI_JSON,  # Forcer JSON uniquement pour l'extraction\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "uO_KfienKd7D"
      },
      "outputs": [],
      "source": [
        "# 3. Texte d'entrée\n",
        "texte = \"\"\"\n",
        "Thomas, 34 ans, est ingénieur en intelligence artificielle chez NeuroTech Systems, une startup spécialisée dans les algorithmes d’apprentissage profond.\n",
        "Il passe ses journées à entraîner des modèles pour optimiser la reconnaissance vocale, souvent en collaboration avec Léa, 29 ans, designer UX chez VirtuaSoft,\n",
        "une entreprise qui développe des interfaces immersives pour la réalité augmentée.\n",
        "Léa s’assure que les utilisateurs interagissent intuitivement avec les IA conçues par des entreprises comme celle de Thomas.\n",
        "De son côté, Karim, 41 ans, est chef de projet chez Quantum Solutions, un cabinet de conseil en innovation technologique.\n",
        "Il supervise des partenariats entre sociétés comme NeuroTech et VirtuaSoft, coordonnant leurs efforts pour créer des expériences utilisateur toujours plus fluides et intelligentes.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9lK4Gi90KkLW"
      },
      "outputs": [],
      "source": [
        "# 4. Préparer le message pour extraire les personnes\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": f\"Extrais toutes les personnes mentionnées dans ce texte: {texte}\",\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "SpmVbPJpKkGf"
      },
      "outputs": [],
      "source": [
        "# 5. Extraction des personnes sous forme de générateur\n",
        "extraction_personnes = client.chat.completions.create(\n",
        "    messages=messages,\n",
        "    response_model=ExtractionPersonnes,  # Attente d'un objet contenant \"personnes\"\n",
        "    max_retries=2,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2x17xIvbKyS4",
        "outputId": "717ba2d1-bbd7-45a5-c11e-649d3d6dc91d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Raisonnement du modèle: \n",
            "\n",
            "J'ai identifié les noms, âges, rôles et compagnies des personnes mentionnées dans le texte. J'ai ensuite créé un objet JSON pour chaque personne, en respectant le schéma fourni. Les informations ont été extraites directement du texte, et j'ai veillé à ce que les types de données soient corrects (par exemple, l'âge est un nombre entier ou une chaîne de caractères).\n",
            "\n",
            "Liste des personnes extraites :\n",
            "\n",
            "Personne 1:\n",
            "Nom: Thomas, Rôle: ingénieur en intelligence artificielle, Compagnie: NeuroTech Systems, Age: 34\n",
            "Ou, directement: nom='Thomas' age=34 role='ingénieur en intelligence artificielle' compagnie='NeuroTech Systems'\n",
            "\n",
            "Personne 2:\n",
            "Nom: Léa, Rôle: designer UX, Compagnie: VirtuaSoft, Age: 29\n",
            "Ou, directement: nom='Léa' age=29 role='designer UX' compagnie='VirtuaSoft'\n",
            "\n",
            "Personne 3:\n",
            "Nom: Karim, Rôle: chef de projet, Compagnie: Quantum Solutions, Age: 41\n",
            "Ou, directement: nom='Karim' age=41 role='chef de projet' compagnie='Quantum Solutions'\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 7. Affichage du raisonnement et des noms et rôles des personnes extraites\n",
        "\n",
        "print(\"Raisonnement du modèle: \\n\")\n",
        "print(extraction_personnes.reasoning)\n",
        "\n",
        "\n",
        "print(\"\\nListe des personnes extraites :\\n\")\n",
        "for i, personne in enumerate(extraction_personnes.list_personnes, start=1):\n",
        "    print(\n",
        "        f\"Personne {i}:\\nNom: {personne.nom}, Rôle: {personne.role}, Compagnie: {personne.compagnie}, Age: {personne.age}\"\n",
        "    )\n",
        "    print(\"Ou, directement: \" + str(personne) + \"\\n\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
